\chapter{Mineração de Dados na WEB} \label{WebMining}

% \section{}
		No inicio, a \textit{Web} continha páginas estáticas objetivando um acesso cômodo as informações. Muitas páginas eram manualmente implementadas, sem contemplar muito a interação com o usuário. Geralmente seguiam a direção servidor-usuário.
		
		Com a expansão e o acesso crescente, as páginas começaram a evoluir, assim como a \textit{Web}. Tornando-se dinâmica, onde encontramos páginas construídas interagindo-se com o usuário. Nos encontramos neste estágio evolutivo, e caminhamos para um futuro muito mais brilhante.
		
		E como a evolução não tem fim, estamos observando a concepção da \textit{Web} Semântica. Onde apenas apresentar as informações para o usuário não é o suficiente, como é preciso, expressar de uma forma semântica também para o entendimento das máquinas.
		 
		Alguns problemas podem ser encontrados pelos usuários quando interagem com a \textit{Web}\cite{Kosala2000}:
  
		 \begin{itemize} 
		   \item[a.] \textbf{Achar informações relevantes} - Os usuários quando utilizam serviços de pesquisa, procuram através de palavras-chaves alguma informação na \textit{Web}. O resultado da busca, as vezes, é enorme e com isso temos: resultados relevantes, pouco relevantes ou sem relevância;
		   
		   \item[b.] \textbf{Personalização da informação} - Usuários diferentes, interagem diferentemente e querem conteúdos diferentes, logo, temos o problema no lado do usuário e do próprio provedor;   
		 \end{itemize}
    
		A \textit{Web Mining} foi concebida devido aos estudos nas mais diversas linhas de pesquisa: extração de informação, inteligência artificial, banco de dados, recuperação de informação e entre outras áreas. Ela faz parte de um todo, que auxiliam de uma maneira para a resolução dos problemas acimas citados.

\section{Web Mining}
	
		\textit{Web Mining} é o uso das técnicas de Mineração de Dados para descobrir e extrair automaticamente a informação de documentos na Web\cite{Etzione1996}. A Mineração de Dados refere-se ao processo não trivial de identificação de padrões válidos, previamente desconhecidos e potencialmente úteis de dados\cite{Frawley1992}. Seguindo o conceito de Etzione, que utiliza da Descoberta do Conhecimento(\textit{Knowledge Discovery Database}) como base, ele decompõe a Web Mining em 4(quatro) tarefas: \emph{Resource finding}(Coleta de Documentos), \emph{Information selection and pre-processing}(Pré-processamento), \emph{Generalization}(Extração de Padrões) e 
\emph{Analysis}(Análise).        		
		
		É importante ressaltar que \emph{Web Mining} é diferente de Recuperação da Informação(\emph{Information Retrieval}) e Extração da Informação(\emph{Information Extraction}). Mas as técnicas são utilizadas nas etapas do \emph{Web Mining}.
		
\section{Descoberta do Conhecimento}

		Muitas são as definições que os pesquisadores adotam para \emph{KDD(Knowledge Discovery Database)} ou Mineração de Dados, a mais difundida e adotada é encontrada nos trabalhos de Fayyad e seu grupo de pesquisa\cite{Fayyad1996a}: 
		\begin{quote}
        	\emph{Knowledge Discovery Database} é o processo não trivial de identificação de padrões válidos, novos, potencialmente úteis e compreensiveis que estejam presentes nos dados.
        \end{quote}

	 	Tomamos como definição que: os \emph{dados} são um conjunto de fatos, e \emph{padrões} são definidos em uma linguagem e descrevem um subconjunto dos dados ou um modelo aplicável aquele conjunto.
	 	
	 	O processo de \emph{Knowledge Discovery Database} é um processo interativo e iterativo, composto por algumas etapas, resultando na extração de padrões. As etapas sofreram mudanças no decorrer de seus estudos, alcançando nove etapas\cite{Fayyad1996b}, sendo reduzida para quatro \cite{Weiss1998} e maturando-se num ciclo [Rezende2003]. Atualmente, este ciclo se divide em: Identificação do problema, Pré-Processamento, Extração de Padrões, Pós-Processamento e Utilização do Conhecimento\cite{Alvarez2007}. A figura~\ref{fig:WM-KDD} ilustra a última abordagem utilizada.
	 	
	 	\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.5]{./figuras/processo-kdd.png}				
			\end{center}
			\caption{Etapas do processo KDD\cite{Rezende2003}}
            \label{fig:WM-KDD}
		\end{figure}
	 	 
	 	 \paragraph{Identificação do Problema} Para iniciarmos o todo o processo, precisamos ter um conhecimento mínimo que seja do dominio com o qual iremos trabalhar, e devemos ter claro o objetivo que almejamos. Nesta fase, construimos nosso conhecimento e todas as etapas posteriores são dependentes de uma análise que cubra as metas, objetivos e restrições. Criamos o conceito de útil para o sistema e para o úsuario nesta fase.
	 	 
	 	 \paragraph{Pré-Processamento} Muitas vezes os dados não se encontram formatados adequadamente para a utilização na etapa de extração de padrões, ou outras características limitam a aplicação. Para adequá-los alguma tarefas podem ser inseridas no Pré-Processamento: Integração, Transformação, Limpeza e Redução de Dados.
	 	 
	 	 	\begin{itemize}
                \item \textbf{Integração:} Os dados muitas vezes são provenientes de diversas fontes, precisando uma unificação. Obtemos nesta fase, uma fonte única de dados para utilizar nas estapas posteriores\cite{Alvarez2007}.
                \item \textbf{Transformação:} Para minimizar as diferenças encontradas nos dados para melhorar sua extração, algumas transformações aplicadas são: normalização, transformação de tipo, discretização de atributos quantitativos, entre outros\cite{Batista2003}.
                \item \textbf{Limpeza:} Com o conhecimento adquirido no passo de Identificação do problema, temos um embasamento melhor para remover dados indesejáveis. Alguns atributos podem estar preenchidos incorretamente\cite{Alvarez2007}.
                \item \textbf{Redução:} Muitas vezes somos obrigados a limitar nossa ação diretamente ligados a inúmeros fatores. O volume pode ultrapassar a capacidade de processamento, sendo isto observado quando executamos muitas vezes os experimentos\cite{Weiss1998}. 
              \end{itemize}
	 	 	
	 	 \paragraph{Extração de Padrões} Os objetivos definidos na Identificação do Problema direcionam este passo. A execução deste passo pode ser necessária muitas vezes para procurar o resultado mais perto do objetivo. As tarefas de Mineração de Dados como classificação, \emph{clustering} e regras de associação são empregadas nesta etapa de acordo com o modelo escolhido para ser gerado\cite{Alvarez2007}.
	 	 
	 	 \paragraph{Pós-Processamento} Depois de extraídos os padrões, o ciclo do processo ainda não é fechado, pois se apresentarmos todos os padrões ao usuário como extraimos, podemos mostrar padrões muito complicados ou que fujam dos objetivos. Com a qualidade questionável podemos executar novamente algumas etapas ou o processo inteiro. Para mensurar a qualidade temos alguns artificios como interessabilidade, compreensibilidade, precisão, cobertura e taxa de erro\cite{Alvarez2007}.
	 	 
	 	 \paragraph{Utilização do Conhecimento} Última fase do processo e onde expomos o conhecimento extraído para o usuário, ou integrar a um sistema.
	 	 
	 	 A utilização dos termos Mineração de Dados ou \emph{Knowledge Discovery Database} na literatura é muito nebulosa. Alguns autores consideram como sendo processos distintos, outros processos que se complementam ou nomeia o mesmo processo. Adoto neste trabalho como sendo tarefas complementares.

\section{Etapas do Web Mining}

		Basicamente utilizamos os mesmos conceitos de \emph{Knowledge Discovery Database} alterando a fonte de dados. Como nossa única fonte, utilizamos a \emph{World Wide Web}. No inicio das pesquisas muitos acreditavam, e ainda acreditam, que a \emph{Web} é muito instável como fonte de dados, devido a suas proporções e falta de estruturação. Muitas informações são encontradas em Linguagem Natural pois o público-alvo são os humanos. Alguns defenderam a posição de transformar a \emph{Web} em um banco de dados, mas foram vencidos pelo temperamento caótico e dinâmico\cite{Etzione1996}.
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.5]{./figuras/kdd.png}				
			\end{center}
			\caption{Etapas do processo de Web Mining}
            \label{fig:WM-processo_WebMining}
		\end{figure}

	\subsection{Coleta de Documentos}
	
		A Coleta de Documentos é uma etapa essencial para todo o processo. Definimos com quais documentos o trabalho sera efetuado. Em algumas situações os documentos fazem parte do problema como um todo, logo estarão disponiveis de inicio. Porém, em outras situações, é necessário o processo de Coleta de Documentos\cite{Alvarez2007}.
		
		Na grande rede mundial interligando computadores, desde seu inicio, houve uma comoção para facilitar a busca de documentos. Dois grandes grupos são observados na construção de indexadores: Motor de Busca e Diretório WWW\cite{Baeza-Yates1998}.
		
		\begin{itemize}
          \item \textbf{Motor de Busca(\emph{Search Engine}):} Este grupo são formados por motores de busca que utilizam abordagens baseados em rôbos, mega-indexadores, entre outras abordagens automatizadas. O índice criado é centralizado para responder consultas do mundo inteiro. Em 1998, os indexadores que cobriam a maior área eram: \emph{HotBot\footnote{HotBot - http://www.hotbot.com}}, \emph{AltaVista\footnote{AltaVista - http://www.altavista.com}}, \emph{Nothern Light\footnote{Nothern Light - http://www.nothernlight.com}}\cite{Lawrence1998}. Atualmente, o ranking é composto por: \emph{Google\footnote{Google - http://www.google.com}}, \emph{AlltheWeb\footnote{AlltheWeb - http://www.alltheweb.com}}, \emph{AltaVista}\cite{Vaughan2004}. Alguns \emph{search engines} se especializam em tópicos, como o \emph{SearchBroker\footnote{SearchBroker - http://www.searchbroker.com}}. Neste grupo, incluimos também os \emph{metaseachers}, que são serviços disponiveis que coletam respostas de diversos \emph{search engines} e unificam. Como exemplos, temos o \emph{MetaCrawler\footnote{MetaCrawler - http://metacrawler.com}} e \emph{SavvySearch\footnote{SavvySearch - http://www.savvysearch.com}}\cite{Baeza-Yates1998}.
 
          \item \textbf{Diretório WWW:} Utiliza uma classificação próxima do conhecimento humano, na representação de diretórios de assunto, que se estruturam como árvores. Uma grande vantagem desta técnica é a resposta ser, na maiora dos casos, útil. A desvantagem é a falta de especialização e volume de páginas classificadas, esta última desvantagem se deve ao crescimento exponencial de informações que são inseridas na \emph{WWW} todos os dias. Um grande exemplo deste grupo é o \emph{Yahoo!\footnote{Yahoo! - http://www.yahoo.com}}\cite{Baeza-Yates1998}.
          
        \end{itemize} 
        
        Um ponto muito importante nesta etapa, é que os documentos coletados estarão na sua maioria em muitos formatos, sendo necessário um tratamento para unificar um padrão.
	
	\subsection{Pré-Processamento}
	
		Após a coleta de todos os documentos possiveis, na etapa anterior, partimos para o pré-processamento destes documentos. É nesta etapa que transformamos uma coleção de documentos em uma representação estruturada adequada. O custo computacional é elevado. Constantemente é adotado a representação de um documento como um conjunto de palavras, chamado de abordagem \emph{bag-of-words}\cite{Alvarez2007}.
		
		\paragraph{Representação de Documentos} A abordagem \emph{bag-of-words} consiste em representar cada documento da coleção como um vetor de termos contidos no mesmo. Cada termo que ocorre no documento pode ser composto por apenas uma palavra ou várias palavras. Para identificar todos os termos presentes, é efetuado uma \emph{tokenização} dos termos\cite{Alvarez2007}. 
		
		\paragraph{Redução de Representação} Feita a representação, podemos ter em mãos um volume enorme para processar, e as vezes, somos limitados no processamento e armazenamento de tanta informação. Com esta finalidade, utilizamos algumas técnicas para auxiliar na redução:
		
			\subparagraph{Filtragem} Na filtragem, almejamos a remoção de termos com pouca ou nenhuma relevância para a análise. Em geral, removemos artigos, preposições e conjunções.
			
			Podemos também supor que termos que aparecem muitas vezes no documento, não revelam muitas informações sobre o documeto. Analogamente, termos que aparecem pouco também podem ser excluidos\cite{Yang1997}.
			
			\subparagraph{\textit{Stemming}} Nos documentos, as palavras podem ser encontradas flexionadas em diversas formas e as vezes compartilham a mesma raiz semântica. O processo de \emph{steamming} consiste em reduzir estas formas encontradas na raiz(\emph{stem}). Podemos citas Porter\cite{Porter1997} e Lovins\cite{Lovins1968} como grandes pesquisadores nesta área. Para a lingua portuguesa, temos o STEMBR : A stemming algorithm for the brazilian portuguese language.

		Filtragem e \emph{Stemming} são apenas algumas das técnicas envolvidas no Pré-Processamento, podemos adotar muitas outras que trabalham no âmbito semântico, hierarquico, com atributos relevantes, etc.
		
		\paragraph{Pré-processamento Linguístico} Esta etapa é essencial em cenários onde a mineração tem como objetivo o reconhecimento de nomes próprios, lugares e organizações, e se faz necessário um pré-processamento linguístico. As seguintes tarefas são adotadas no processo:
		
		\begin{itemize}
		  \item \textbf{Etiquetagem morfossintática(\emph{Part-Of-Speech Tagging})} No texto, encontramos palavras, símbolos, fórmulas matematicas, entre outros termos. A etiquetagem morfossintática tem como tarefa atribuir uma etiqueta para cada termo encontrado de acordo com sua categoria. 
		  
		  \item \textbf{Reconhecimento de frases} Com o agrupamento de termos, analisando o documento, tem como objetivo formar sentenças\cite{Weiss1998}.
		  
		  \item \textbf{Desambiguação no sentido de palavras} A ambiguidade pode gerar transtornos em análises futuras, por isto, procura-se eliminar qualquer ambiguidade no sentido das palavras. Em algumas linguas essa eliminação é facilmente alcançada, porém, outras precisam de um conhecimento muito mais aprofundado na própria lingua e o dominio da aplicação.
		  
		  \item \textbf{\emph{Parsing}} Com a geração da árvore sintática de uma sentença, criamos a possibilidade de analisarmos a relação existente entre as palavras da sentença. Podemos extrair o sujeito, objeto, entre outros, analisando a função exercida pela palavra no contexto da senteça\cite{Alvarez2007}. 
		   
        \end{itemize}
        
        As técnicas são frequentemente utilizadas visando uma melhoria para a utilização na Mineração de Dados.
						
	\subsection{Extração de Padrões}
	
		Após o tratamento dos documentos e seus dados, temos como resultado um conjunto em formatos que terão um aproveitamento melhor para a Extração de Padrões. Com a aplicação da Extração de Padrões a obtenção de um conhecimento útil e interessante para o usuário será possivel.
		
		Algumas tarefas relacionadas com a Mineração de Dados, utilizam muitos algoritmos de Aprendizado de Maquiná, que também são utilizados na Extração de Padrões.
		
		\paragraph{\emph{Clustering} de Documentos} Com a coleção de documentos em mão, o processo de agrupar os documentos similares, agrupando assim documentos com conteúdos relativamente similares. Estes grupos recebem o nome de \emph{cluster}, e o processo de \emph{Clustering} de Documentos. No final deste processo, teremos cluster com documentos similares, mas clusters distintos entre si\cite{Zhong2003}.
		
		\paragraph{Categorização} A partir de um conjunto de classificação pré-definido, com um documento novo induzimos um classificador a enquadra-lo numa categoria. Muitas dificuldades são encontradas, pois o documento pode pertencer a nenhum, uma ou mais categorias\cite{Yang1997}.
		
		\paragraph{Extração de Informação} Como Wilks define, Extração de Informação, extrai informação de textos em documentos, utilizando computadores numa velocidade alta, e normalmente encontrada de fontes eletrônicas. Prece de uma fase de Recuperação de Informação, que seleciona um conjunto apropriado para a extração\cite{Wilks1997}. Extração de Informação é discutido no capítulo~\ref{EI}.
		
		\paragraph{Sumarização} O processo de Sumarização consiste em construir um terceiro documento contendo um sumário com as informações mais importantes do documento análisado, buscando sempre que este sumário contenha metade ou menos do tamanho do documento original. Identificar partes importantes no documento continuam sendo um grande desafio nesta área\cite{Radev2002}.
		
		Extração de Informação e Mineração de Dados partilham algumas dificuldades como a estruturação do documento, a língua e o estilo de linguagem utilizada na formatação do documento, e o próprio conteúdo do documento.  
			
	\subsection{Avaliação e Interpretação de Resultados}
	
		Para concluirmos o ciclo ou refazer algumas etapas, avaliamos o quanto o processo se aproximou do objetivo almejado. A avaliação pode ser feita pelos usuários finais ou especialistas, que possuem um conhecimento profundo do dominio\cite{Alvarez2007}.
		
		Algumas das métricas são compartilhadas com a Extração de Informação, como Precisão, Cobertura ou \emph{F-measure}. Elas são abordadas no capitulo~\ref{EI} na seção~\ref{EI:avaliacao}.
		
		Para melhor avaliação a ilustração dos dados em elementos gráficos pode, e muito, auxiliar a análise e compreensão dos dados por seres-humanos. Conseguimos interpretar, armazenar muito mais informações gráficas do que tabelas, diferentemente das máquinas. Podemos trabalhar com dados muito mais complexos através de gráficos, podendo assim interagir com decisões muito mais rápidas. O tipo de gráfico empregado para a visualização é de extrema importância, uma vez que se escolhermos gráficos que sejam difíceis de interpretar, em nada ajudarão na avaliação\cite{Keim2002}.

\section{Categorias de WEB Mining}
		
		Com o crescimento exponencial das fontes de informação disponiveis na \emph{World Wide Web} ao nosso redor, cresce a necessidade de automatizar ferramentas que busquem as informações desejadas e corretamente. Ferramentas mais eficazes no rastreamento, tanto do lado dos servidores como dos clientes, são comumente alvos de pesquisas e projetos na busca de uma mineração de dados. Do lado dos servidores, temos extesas listas de \emph{logs}, registros de usuários ou perfil de usuário, entre outros itens que podem ser análisados\cite{Cooley1997}. Na figura~\ref{fig:WM-toxonomia} podemos observar um esboço da taxonomia.  
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.6]{./figuras/WB-taxonomia.png}				
			\end{center}
			\caption{Taxonomia da Mineração na WEB}
            \label{fig:WM-toxonomia}
		\end{figure}

		Esta taxonomia pode ser montada através da junção dos trabalhos de Cooley\cite{Cooley1997} e Kolari\cite{Kolari2004}.
	
		\subsection{Mineração de Conteúdo}\label{webmining:conteudo} 
		
		A falta de estruturação que domina as fontes de informação na \emph{Internet} dificulta a organização, administração, manutenção e busca automatizada de informação. As \emph{search engines} são ferramentas que provêm algum conforto, mas geralmente não filtram, interpretam os documentos que retornam nas buscas\cite{Cooley1997}.
		 
		 A Mineração de Conteúdo e a Recuperação de Informação são muitas vezes utilizadas em conjunto. Enquanto uma realiza a mineração diretamente do conteúdo dos documentos a outra incrementa o poder de busca de outras ferramentas e serviços. Áudio, vídeo, dados simbólicos, metadados e vínculos de hipertexto fazem parte do conteúdo de documentos da \textit{Web} atualmente, e como tal, na mineração de conteúdos também são analisados.
		
		Com o continuo crescimento da \emph{Web}, as pesquisas voltadas para ferramentas mais eficazes, melhorias nas técnicas de mineração e extração de dados se desenvolveram. Podemos observar duas grandes abordagens quando tratamos de Mineração de Conteúdo: Baseado em Agente(\emph{Agent-Based}) e Banco de Dados(\emph{Database}).
		 
		\paragraph{Baseado em Agente(\emph{Agent-Based})} Esta abordagem de mineração de dados trabalha diretamente com o campo de Inteligência Artificial, provendo um sistema autônomo ou semi-autônomo, que trabalha para a coleta de conhecimento e organização das informações na \emph{WEB} delimitado pelo escopo do sistema. Dentro desta abordagem, temos as seguintes categorias: 		
		
			\subparagraph{Agentes de Busca Inteligentes(\emph{Intelligent Search Agents})} Muitos sistemas de Agentes Inteligentes utilizam informações caracteristicas de um domínio para organizar e interpretar essas informações de uma forma totalmente autônoma. Como exemplo, temos alguns trabalhos como o \emph{Harvest}\cite{Bowman1995}, \emph{FAQ-Finder}\cite{Hammond1994}, \emph{OCCAM}\cite{Kwok1996} e \emph{ParaSite}\cite{Spertus1997} que extraem e interpretam documentos através de um dominio específico. Outros agente como \emph{ShopBot}\cite{Etzione1997} e \emph{ILA(Internet Learning Agent)}\cite{Etzione1995} através de estruturas de fontes de informação não familiares tentam através da interação, aprender novos comportamentos. \emph{ShopBot} coleta informações de produtos em vários sites de venda utilizando apenas informações gerais dos produtos, enquanto o \emph{ILA} aprende com os modelos e traduz para um conceito interno do sistema\cite{Cooley1997}.
								
			\subparagraph{Categorização e Filtragem de Informação} Muitos agentes \emph{Web} utilizam tecnicas de Recuperação de Informação para automaticamente filtrar e categorizar documentos da Web. O \emph{BO(Bookmark Organizer)} combina técnicas de \emph{clustering} e interação com o usuário para orgazinar o conjunto de documentos baseado em informação conceitual\cite{Maarek1996}. O HyPursuit usa informação semântica embutida nos links e no conteúdo em si dos documentos para criar uma hierarquia de \emph{cluster} de hipertextosm e estruturar as informações\cite{Weiss1996}.
			
			\subparagraph{Personalização} Outra categoria de agentes Web incluem aqueles que obtêm ou aprendem as preferencias do usuário e procuram fontes de informação na \emph{Web} que correspondam aquelas preferências, e possivelmente, utilizando filtragem colaborativa, procuram interesses similares. Exemplos que utilizam esta abordagem são \emph{WebWatcher}\cite{Freitag1995}, \emph{PAINT}\cite{Wiggins1994}, \emph{Firefly}\cite{Shardanand1995} e \emph{Syskill\&Webert}\cite{Pasani1996}.
						 
		\paragraph{Banco de Dados(\emph{Database})} A abordagem de Banco de Dados, como o nome pressupõem, trabalha com a organização e integração dos documentos semi-estruturados para um documento estruturado, como em um banco de dados relacional, usando inclusive consultas e mecanismos de banco de dados para acesso e analise das informações.
		
			\subparagraph{Banco de Dados em Multiníveis} Uma organização das informações em multiníveis é proposto por muitos pesquisadores. No nível principal são encontrados informações armazenadas de forma semi-estruturadas em vários repositórios na \emph{Web}. Em níveis acima do principal, encontramos meta-dados ou generalizações que são extraídas das camadas abaixo e organizadas de forma com uma estrutura rigida como um modelo relacional ou orientado objeto\cite{Cooley1997}. Em uma das pesquisas desenvolvidas por Han e seu grupo de pesquisa, utilizam um banco de dados de multi-camadas onde cada camada é obtida com operações de transformações e generalização das camadas inferiores\cite{Han1995}. O sistema ARANEUS extrai informações relevantes de documentos de hipertexto e integra em documentos derivados de hipertexto que são generalizações de \emph{views} de banco de dados\cite{Merialdo1997}.
			
			\subparagraph{Sistemas de Consulta Web(\emph{Web Query Systems})} Nesta abordagem, a utilização de \emph{queries} são utilizadas 
		
			
			\subparagraph{Web Query Systems}: There have been many Web-base query systems and languages developed recently that attempt to utilize standard database query languages such as SQL, structural information about Web documents, and even natural language processing for accommodating the types of queries that are used in World Wide Web searches. We mention a few examples of these Web-base query systems here. W3QL [KS95]: combines structure queries, based on the organization of hypertext documents, and content queries, based on information retrieval techniques. WebLog [LSS96]: Logic-based query language for restructuring extracted information from Web information sources. Lorel [QRS95] and UnQL [BDS95,BDHS96]: query heterogeneous and semi-structured information on the Web using a labeled graph data model. TSIMMIS [CGMH94]: extracts data from heterogeneous and semi-structured information sources and correlates them to generate an integrated database representation of the extracted information.
			
			 
		
		 Existem áreas de pesquisas destinadas a mineração de dados multimídias, entretanto, como uma enorme parte da \textit{Web} é constituída de texto e hipertexto, portanto o foco permanece em dados de texto. Estes podem ser encontrados em três tipos: desestruturados (textos), semi-estruturados (\textit{HTML}) e estruturados (\textit{XML}).
	 
		A área de mineração de textos está bem esclarecida, com muitas técnicas, uma das quais seria reestruturar o documento para uma linguagem entendida pela maquina. Uma mineração que vem ganhando destaque em pesquisas é a mineração em serviços da Web tais como grupo de noticias, grupos de e-mails, lista de discussão. Outro conceito é introduzido por estes pesquisadores, chamado de \textit{Web Intelligence}, que promete transformar os serviços da \textit{Web} em entidades inteligentes, de forma que elas possam interagir e se comunicar através de uma linguagem comum. 
			
		Duas abordagens são utilizadas na mineração de conteúdo, utilizando agentes ou baseadas em banco de dados. As baseadas em banco de dados procura transformar os dados da Web em modelos estruturados para facilitar o trabalho.  

		\subsection{Mineração de estrutura}\label{webmining:estrutura} - Como o próprio nome descreve, nesta categoria de mineração estamos preocupados com a estrutura dos documentos \textit{Web} e como estes estão ligados entre si. Os vínculos de ligação de hipertexto são os principais objetos de estudos nesta categoria. Podemos visualizar a \textit{Web} como um grafo orientado, onde os nós representam páginas e as setas entre os pares de nós representam os vínculos entre as paginas. Como ocorre em citações bibliográficas quando um artigo é bastante citado indicando que provavelmente este artigo tem um peso importante perante outros que abordam o mesmo tema, o mesmo pode ser observado entre os documentos \textit{Web}. Podemos drasticamente comparar que se uma pagina tem muitas setas entrando, ela teria certa relevância quanto ao seu conteúdo ser confiável. 

 		\subsection{Mineração de uso}\label{webmining:uso} - A mineração de uso utiliza os dados secundários provindos de logs de servidores, logs de browsers, perfis de usuário, cookies, seções ou transações de usuários, pasta favoritos, consultas do usuário, cliques de mouse e qualquer outro dado gerado pela interação do usuário com a \textit{Web}. As aplicações da mineração de dados de uso são classificadas em duas categorias: aprendizado de perfil de usuário (modelagem em interfaces adaptativas) e aprendizado de padrões de navegação de usuário. Talvez umas das técnicas em mais utilização atualmente, devido ao grande número de e-commerce, pois com isto podemos adaptar sites de acordo com o cliente, recomendar produtos de acordo com compras passadas ou baseadas nas similaridades entre perfis de usuários. 

        \subsection{Web Semântica}\label{webminig:semantica}

		A mineração em dados provindos da Web é multidisciplinar, pois muitas áreas são utilizadas como: recuperação de dados, aprendizagem de maquina, agentes de informação. Uma área muito vasta de interessante pesquisa, e com um futuro muito promissor, pois dia após dia vemos a Web crescer e por enquanto, seu horizonte parece não ter fim. 