\chapter{Extração de Informação} \label{capitulo4}

		Nós, simples seres humanos, não temos a capacidade de processar \textit{megabytes} de texto todos os dias, e nesse mar de bytes, quantas oportunidades estariamos perdendo ou informações perdidas? Projetos em Processamento de Linguagem Natural originaram a Extração da Informação. Extração de Informação tem como objetivo transformar a coleção de documentos, geralmente com o auxilio de um sistema de Recuperação de Informação, em informação que é facilmente analisada e digerida\cite{Lehnert1996}. Na Extração da Informação, a compreensão do texto fonte não é obrigatória, pois a analise é feita com o objetivo de encontrar porções que contenham o quê deve ser extraido. A sáida de um sistema de Extração da Informação são informações relevantes para o domínio específico, de acordo com as orientações iniciais.

		O reconhecimento de palavras, análise de frases, compreensão do sentindo da frase ou de todo o documento são envolvidos nas pesquisas de processamento de linguagens, e aumentam a complexidade no desenvolvimento de um sistema de Extração da Informação. Um grande alavancador nas pesquisas em Extração da Informação foram os congressos \textit{MUC(Message Understanding Conferences)} que eram financiadas pelo \textit{DARPA(Defense Advanced Research Projects Agency)}\cite{Sundheim1991}.
				
		Os participantes puderam optar pelo formato de saída apenas no MUC-1. Da segunda conferência em diante, o formato de saída era determinado pelo cômite organizador. Alguns campos típicos relacionados eram: causa, agente, lugar e tempo de um evento, consequências, etc. A cada conferência crescia o número de campos. Reconhecimento de Entidades Relacionadas e Co-referencia foram adicionadas na sexta conferência.
						
% Tabela dos MUC
\begin{table}[htbp]
  \centering   
    \begin{tabular}{rrrr}
    \addlinespace
    \toprule
    {\bf Conferência} & {\bf Ano} & {\bf Fonte de Texto} & {\bf Tópico(Dominio)} \\
    \midrule
    MUC-1 & 1987  & Artigos Militares &  \\
    MUC-2 & 1989  & Artigos Militares &  \\
    MUC-3 & 1991  & Artigos de Jornais & Atividades Terroristas na América Latina \\
    MUC-4 & 1992  & Artigos de Jornais & Atividades Terroristas na América Latina \\
    MUC-4 & 1993  & Artigos de Jornais &  \\
    MUC-6 & 1995  & Artigos de Jornais &  \\
    MUC-7 & 1997  & Artigos de Jornais & Acidente de aviões e lançamento de foguetes \\
    \bottomrule
    \end{tabular}
	\caption{MUC}
  \label{tab:addlabel}
\end{table}

		Os critérios de avaliação consistiam em:
		
		
<------------->
		A complexidade no desenvolvimento de um sistema de EI origina-se dos requerimentos de processamento de linguagem envolvidos no reconhecimento de palavras e análise de frases, bem como da compreensão ao nível de frase, e da análise de discurso até o nível de todo o documento. A pesquisa em EI foi alavancada pelos congressos Message Understanding Conferences (MUC) (Sundheim, 1991, 1992, Lehnert, & Sundheim, 1991). O método empregado pelo laboratório de processamento de linguagem natural da Universidade de Massachusetts (Lehnert, 1996) ao participar dos MUCs (MUC-3, 1991, MUC-4, 1992, MUC-5, 1993) é bastante adequado para aplicações onde a precisão das classificações é mais importante do que o reconhecimento de cada documento. Os principais tópicos que foram objeto de pesquisa por este grupo foram análise de frase (Cardie e Lehnert, 1991), rotulagem semântica (semantic tagging) (Cardie, 1993), construção de dicionários (Riloff & Lehnert, 1993, Riloff, 1993), e classificação de texto (Riloff & Lehnert, 1992 e 1994).
 
		Extração de Informação baseada em conhecimento
		
		O papel de padrões lingüísticos é sustentar a interpretação de textos na Extração de Informação baseada em conhecimento. Em função da construção de padrões lingüísticos ser um gargalo mesmo em domínios limitados, propôs-se o uso de um mecanismo de aprendizagem indutivo para construir automaticamente uma base de conhecimento de padrões. O sistema automático é construído sempre que se identifica um padrão lingüístico desconhecido. Um pressuposto importante embasando esta pesquisa é o reduzido número de expressões normalmente utilizado para descrever uma informação dentro de um domínio limitado (Kim & Moldovan, 1995).
 
		Template Mining
		
		Template Mining ou mineração por modelos é uma técnica de processamento de LN que extrai dados de textos que possuem padrões que permitam o reconhecimento do que se deseja extrair ou de seus arredores. Um modelo contém informação sobre o que procurar no texto e é disparado a extrair determinadas partes devidamente indicadas. Lawson et al., (1996) descreve aplicações de template mining em domínios restritos alegando que esta técnica é própria para áreas cujos textos são claros com frases objetivas e de natureza declarativa.
 
		Text windowing
		
		A técnica text windowing é do tipo orientada para corpus de textos que avalia palavras na busca de blocos de palavras que estejam relacionadas por sintática ou propriedades léxicas. Jacquemin (1996), descreve uma aplicação de text windowing em um método para selecionar trechos de textos motivados por propriedades léxicas, combinando informação conceitual em listas de termos com metaregras em filtros semânticos locais.
 
		Documentos Auto-Explicativos
		
		Consideramos adequado associar a técnica de template mining com a metodologia proposta por Branting & Lester (1996) para documentos auto-explicativos. Nesta metodologia, os textos são analisados e classificados por sua estrutura retórica. A ligação entre as técnicas se dá pelo aproveitamento das estruturas retóricas como fonte para a definição dos parâmetros dos modelos usados pela técnica de template mining para extração de dados.
 
		Aquisição de Conhecimento de Textos
		
		O trabalho publicado pelo Grupo de Engenharia de Conhecimentos de Textos da Universidade de Freiburg através de diversos artigos descreve os esforços para analisar textos que apresentam novas formas de conhecimento. O grupo se utiliza de um parser de LN e almeja a expansão desta base de conhecimento. Da mesma forma que os grupos que tomaram parte dos MUCs, eles também usam técnicas com modelos; entretanto, eles permitem que novos modelos sejam adicionados como resultado da aprendizagem de conceitos (Hahn, & Schnattinger, 1997).

		O ponto central da pesquisa do grupo trata-se da aquisição de conhecimento de textos que ocorre com a aprendizagem de conceitos que alimenta um sistema de compreensão de linguagem natural. A aprendizagem de conceitos em uma plataforma de compreensão de linguagem natural é orientada para os recursos através do uso de um Machine Readable Dictionary MRD e é orientada por contexto. Os autores alegam que inferir o significado das palavras baseando-se em informações sobre o contexto é mais confiável do que procurar por seu significado em um MRD. A aprendizagem de conceitos é concebida com o desenvolvimento de uma abordagem de aprendizagem de raízes simbólicas. Um exemplo de aquisição de conceito é descrito em Hahn et al. (1996). O projeto do grupo visa duas aplicações práticas de aquisição de conhecimento de textos da língua alemã: artigos sobre testes de produtos de tecnologia de informação (100 documentos com 10^5 palavras) e artigos sobre descobertas médicas (120,000 documentos com $$10^7 palavras).

		O trabalho descrito por Mauldin (1991) usa a compreensão parcial de textos obtida através de um parser que realiza text skimming para recuperação de informação conceitual, utilizando um banco de dados de scripts que, por sua vez, é alimentado por um método de aprendizagem e um MRD que aprimora o conhecimento léxico. A recuperação de informação executada pelo sistema ferret é referida como recuperação de informação conceitual porque ao invés de realizar a busca através do uso de palavras-chave (baseada em palavras) é usado conhecimento sobre os conceitos.

		Um ponto de vista interessante sobre o problema de aquisição de conhecimento de textos é descrito em Futrelle & Zhang (1994) que apresenta técnicas de bootstrap que podem descobrir a estrutura de ordem da linguagem natural e definir classes de palavras presentes em corpus de textos. A definição de classes de palavras é baseada no princípio da substituição onde o significado de uma palavra é encontrado pela comparação dos contextos onde as palavras aparecem e onde elas podem ser substituídas por outra palavra da mesma classe. 