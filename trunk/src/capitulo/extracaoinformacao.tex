\chapter{Extração de Informação} \label{EI}

		Nós, simples seres humanos, não temos a capacidade de processar \textit{megabytes} de texto todos os dias, e nesse mar de bytes, quantas oportunidades deixamos de aproveitar ou informações que estariamos perdendo? Projetos em Processamento de Linguagem Natural originaram a Extração da Informação. Extração de Informação tem como objetivo transformar a coleção de documentos, geralmente com o auxilio de um sistema de Recuperação de Informação, em informação que é facilmente analisada e digerida\cite{Lehnert1996}. Na Extração da Informação, a compreensão do texto fonte não é obrigatória, pois a analise é feita com o objetivo de encontrar porções que contenham o quê deve ser extraido. A sáida de um sistema de Extração da Informação são informações relevantes para o domínio específico em um determinado formato pré-estabelecido de acordo com as orientações iniciais.
		
		A Extração da Informação é uma tarefa mais limitada do que a "compreensão completa do texto". Na Extração da Informação, nós delimitamos o escopo, estabelecendo assim um limite de compreensão, assim, não necessitando analisar o texto completo e seu sentido\cite{Grishman1997}. A Extração da Informação tem um potencial muito grande em extrair dados com maior precisão. Existe um interesse muito grande nas pesquisas em relação a Extração de Informações, uma vez que encontramos uma enorme quantidade de informações em linguagem natural.

		O reconhecimento de palavras, análise de frases, compreensão do sentindo da frase ou de todo o documento são envolvidos nas pesquisas de processamento de linguagens, e aumentam a complexidade no desenvolvimento de um sistema de Extração da Informação.

\section{Extração de Informação não é Recuperação de Informação}\label{EI:EIxRI}

		Recuperação de Informação é uma tecnologia madura que perdura a muito mais tempo do que a Extração da Informação, que apenas começou a poucas décadas. O objetivo da Recuperação de Informação é selecionar documentos relevantes de uma coleção de documentos de acordo com as necessidades do usuario e suas entradas.
		
		O contraste entre os objetivos dos sistemas de Extração da Informação e Recuperação de Informação podem ser descritos como seguem: Recuperação de Informação recupera documentos relevantes de uma coleção, enquanto Extração de Informação extrai informações relevantes de documentos. Consequentemente, as duas tecnicas se complementam, e usadas em combinação podem prover uma ferramenta poderosa[24]\cite{Eikvil1999}.
		
		Recuperação da Informação teve muita influência em 
		
\section{MUC - Message Understanding Conference}\label{EI:MUC}
		
		Quando estudamos Extração da Informação, devemos citar um grande alavancador nas pesquisas em Extração da Informação, os congressos \textit{MUC(Message Understanding Conferences)} que eram financiadas pelo \textit{DARPA(Defense Advanced Research Projects Agency)}\cite{Sundheim1991}. \textit{MUC} foi assim chamado por processar mensagens militares, e consistia em uma troca de experiências entre os participantes, avaliadores e especialistas do governo que descreviam suas necessidades. Surgindo em meados dos anos noventa, ela instaurou métricas e algoritmos estatísticos para auxiliar o governo na avaliação de novos sistemas de Extração de Informação.
				
		Na avaliação dos MUC, uma descrição detalhada do cenário e quais informações a serem extraidas era dado aos participantes, junto com um conjunto de documentos e o modelo a ser extraido dos documentos. Os participantes tinham um tempo limitado\footnote{Geralmente de 1 mês a 6 meses.} para adaptar os sistemas para um novo cenário. Então uma nova coleção de documentos era passado para os participantes, e estes enviavam para os organizadores os resultados extraídos. E assim a avaliação era feita, comparando o gabarito com os resultados extraídos.
	
		Na tabela~\ref{tab:MUC} temos as conferências, e os temas. 
		% Tabela dos MUC
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Conferência} & {\bf Ano} & {\bf Fonte de Texto} & {\bf Tópico(Dominio)} \\
		    \midrule
		    MUC-1 & 1987  & Artigos Militares &  Operações de fuga\\
		    MUC-2 & 1989  & Artigos Militares &  Operações de fuga\\
		    MUC-3 & 1991  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-4 & 1992  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-4 & 1993  & Artigos de Jornais &  \\
		    MUC-6 & 1995  & Artigos de Jornais &  \\
		    MUC-7 & 1997  & Artigos de Jornais & Acidente de aviões e lançamento de foguetes \\
		    \bottomrule
		    \end{tabular}
			\caption{MUC}
		  \label{tab:MUC}
		\end{table}
				
		Os participantes puderam optar pelo formato de saída apenas no MUC-1. Da segunda conferência em diante, o formato de saída era determinado pelo cômite organizador. Alguns campos típicos relacionados eram: causa, agente, lugar e tempo de um evento, consequências, etc. Existiam cinco tarefas importantes para a Extração de Informação dentro das \emph{MUC}: Named Entity Recognition, Coreference resolution, template element construction, template relation construction e scenario template production\cite{Chang2006}.

\section{Fundamentos}\label{EI:fundamentos}

		Nós podemos dividir o processo de Extração de Informação em duas grandes partes. Primeiramente extraimos \emph{fatos} individuais do texto através de uma analise textual. Então, integramos estes fatos, aumentando os fatos ou criando fatos novos. E por fim, os fatos pertinentes ao cenário, nós transformamos para o formato de saída\cite{Grishman1997}.
		
		O alvo da extração de uma Extração de Informação pode ser uma relação de \emph{n-tuplas} ou muito mais complexa considerando a hierarquia e organização dos dados. Programas que realizam a tarefa de Extração de Informação são usualmente chamados de \emph{extratores} ou \emph{wrappers}. Sistemas de Extração da Informação são \textit{softwares} que geram \emph{wrappers}. Um \emph{wrapper} geralmente executa a tarefa de encontrar padrões, e estes dependem de um conjunto de regras. Adaptar um sistema de Extração da Informação tem muitos pontos a serem observados: tipo de texto, domínio, cenário, conjunto de regras\cite{Chang2006}.
		
		O processo da Extração de Informação, geralmente, inicia-se com uma analise lexica e reconhecimento de nomes. Seguidamente por uma analise sintatica completa ou por formas parciais para identificar grupo de nomes, grupo de verbos. Após completado estes passos, damos inicio a procura de fatos interessantes através de padrões. A fase de integração examina e combina os fatos do documento inteiro\cite{Grishman1997}.
		
		A maior parte da analise do texto é feita através de um conjunto de expressões regulares. Se a expressão encontrada estiver inserida no conjunto de expressões regulares, tão logo ela receberá um marcador, e dependendo do sistema, outros recursos.
		
		O Reconhecimento de Nomes em um texto é uma tarefa de destaque, uma vez que nomes aparecem frequentemente em todos os tipos de texto, e de muitas maneiras. Os nomes aparecem em um conjunto de padrão, podendo conter prefixo ou sufixo, estar escrito com letras maíusculas, facilitando assim sua extração. Observando a tabela~\ref{tab:exemplos_nome}, temos algumas maneiras de como o nome João José da Silva Pereira Junior pode aparecer em um texto.

		% Tabela com exemplos de aparição de nomes
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Exemplos de aparição de nomes} \\
		    \midrule
		    João José da Silva Pereira Junior \\ 
		    João José da Silva Pereira Jr. \\
		    João J. da Silva Pereira Jr. \\
		    João J. S. P. Jr.\\
		    Sr. João Pereira Jr. \\
		    JOÃO JOSÉ DA SILVA PEREIRA JUNIOR \\
		    JUNIOR, João J. S. P.		    
		    \bottomrule
		    \end{tabular}
			\caption{Exemplos de aparição de nomes}
		  \label{tab:exemplos_nome}
		\end{table}

		Alguns sistemas não tem fases distintas para léxica e sintatica, outros implementam um \emph{parser} para a sentença inteira. Em geral, os sistemas utilizam partes que possuem certeza sobre sua construção, tanto sintaticamente quanto semânticamente. Na analise sintática, podemos ainda ter muitas interpretações ambíguas, para tal, a semântica e o domínio especifico da aplicação eliminam outras interpretações do dados extraídos.
		
		Construir uma estrutura completa de analise sintática é extremamente dificil. Algumas decisões são particularmente difíceis e dependem do contexto. \emph{Parsers} que buscam avaliar sentenças inteiras pecam no aspecto das decisões locais. Se as relações sintaticas forem corretamente para o passo seguinte da analise, a interpretação dos modelos de cenário serão mais simples e corretas.
		
		 

\section{Avaliação}\label{EI:avaliacao} 
		
		Os critérios de avaliação consistem em: quanta informação foi extraída(\textit{recall}), quanto da informação extraída é correta(\textit{precision}) e quanto da informação extraída é supérflua(\textit{overgeneration})\cite{Sundheim1991}. As conferência \textit{MUC} têm um papel fundamental na definição dessas medidas, na necessidade de avaliar os sistemas de Extração de Informação. Inicialmente as medidas de precisão e cobertura foram herdadas do sistema de avaliação de Recuperação de Informação. Como as técnicas de Extração e Recuperação são distintas, os nomes foram mantidos, porém as definições das medidas foram alteradas\cite{Wilks1998}.
		 
		\begin{itemize}
          	\item \textbf{Cobertura ou Abrangência}(\textit{Recall}) : Quanto da informação extraída é relevante. Ou seja, é medida através da informação corretamente extraída($N_{extraido-correto}$) sobre a informação relevante na página($N_{total-extraidos}$). Representada pela fórmula~\ref{formula:cobertura}
          	
          	\begin{equation}\label{formula:cobertura}
              Cobertura = \frac{N_{extraido-correto}}{N_{total-extraidos}}              
            \end{equation}            
    	
          	\item \textbf{Precisão}(\textit{Precision}) : Quanto da informação extraída é correta. É obtida através da informação corretamente extraída($N_{extraido-corretos}$) sobre a informações extraídas($N_{resposta}$).
          	
          	\begin{equation}\label{formula:precisao}
              Precisão = \frac{N_{extraido-correto}}{N_{resposta}}
            \end{equation}
						
			Importante ressaltar que $N_{total-extraido}$ e $N_{resposta}$ são inversamente proporcionais, isto é, quando a \emph{Cobertura} aumenta, a \emph{Precisão} tende a diminuir e vice-cersa. \emph{Precisão} e \emph{Cobertura} estão sempre no intervalo de $[0, 1]$, sendo 0 o pior resultado e 1 o melhor.
			  
  		 	\item \textbf{\textit{F-measure}} : A \textit{F-measure} mede considerando a precisão e a cobertura. O parâmetro $\beta$ quantifica a preferência da cobertura sobre a precisão. 
  		 	
  		 	\begin{equation}\label{formula:F-measure}
              F-measure = \frac{(\beta^2 + 1)*C*P}{\beta^2 * (C + P)}
            \end{equation}

			Geralmente utilizamos $\beta = 1$ , balanceando assim as duas medidas, e aplicando na fórmula~\ref{formula:F-measure} temos:
			 
  		 	\begin{equation}\label{formula:F1}
              F_1 = \frac{2*C*P}{C + P}
            \end{equation}			   
  		 		 
        \end{itemize} 
		 
		Para ilustrar melhor os cálculos, utilizando a ferramenta \emph{NameParser} criada para o projeto \textit{Salus Cyted}, que será discutida no capitulo~\ref{Capitulo 5}. A ferramenta será aplicada na página  \textit{Association Alzheimer\footnote{Association Alzheimer - http://www.alz.org/}}, vista na figura~\ref{fig:siteAssociationAlzheimer} como nossa fonte de dados. 
		
			\begin{figure}[htb]
				\begin{center}				
					\includegraphics[scale=0.25]{./figuras/site_nome_grifado.png}				
				\end{center}
                \label{fig:siteAssociationAlzheimer}
			\end{figure}

		Temos como resultante a tabela ~\ref{tab:resultados_alzheimerassociation}.
				
            \begin{table}[htbp]
              \centering              
                    \begin{tabular}{rr}
                        \addlinespace
                        \toprule
                              & Página \\
                        \midrule                              
                                Nomes presentes & 16 \\
                                Nomes identificados pelo programa (usando expressões) & 83 \\
                                Nomes corretamente identificados (usando expressões) & 16 \\
                                Precisão  Precision & 100\% \\
                                Cobertura(Abrangência)  Recall & 19\% \\
                              &  \\
                        \bottomrule
                    \end{tabular}
                \caption{Resultados da extração}
              \label{tab:resultados_alzheimerassociation}
            \end{table}

        Interpretando os dados, nossa precisão é altíssima conseguindo obter todos os nomes presentes na página, porém extraímos muitas outras informações irrelevantes. Aplicando a $F_1$, temos um aproveitamento de 31\%, um resultado animador mas muito longe do ideal esperado.
        
        Devemos lembrar também que o domínio atribuido ao resultado é muito importante, por exemplo, se encontrarmos um nome pela metade, devemos considerá-lo errado ou correto? Quando o nome se repete ao longo do página, devemos conta-lo apenas uma vez ou mais vezes? Questões assim dificultam o critério e devem ser relevadas para uma melhor interpretação dos dados.
        
				
		%Extração de Informação baseada em conhecimento 
		
		%O papel de padrões lingüísticos é sustentar a interpretação de textos na Extração de Informação baseada em conhecimento. Em função da construção de padrões lingüísticos ser um gargalo mesmo em domínios limitados, propôs-se o uso de um mecanismo de aprendizagem indutivo para construir automaticamente uma base de conhecimento de padrões. O sistema automático é construído sempre que se identifica um padrão lingüístico desconhecido. Um pressuposto importante embasando esta pesquisa é o reduzido número de expressões normalmente utilizado para descrever uma informação dentro de um domínio limitado (Kim & Moldovan, 1995).
 
		%Template Mining
		
		%Template Mining ou mineração por modelos é uma técnica de processamento de LN que extrai dados de textos que possuem padrões que permitam o reconhecimento do que se deseja extrair ou de seus arredores. Um modelo contém informação sobre o que procurar no texto e é disparado a extrair determinadas partes devidamente indicadas. Lawson et al., (1996) descreve aplicações de template mining em domínios restritos alegando que esta técnica é própria para áreas cujos textos são claros com frases objetivas e de natureza declarativa.
 
		%Text windowing
		
		%A técnica text windowing é do tipo orientada para corpus de textos que avalia palavras na busca de blocos de palavras que estejam relacionadas por sintática ou propriedades léxicas. Jacquemin (1996), descreve uma aplicação de text windowing em um método para selecionar trechos de textos motivados por propriedades léxicas, combinando informação conceitual em listas de termos com metaregras em filtros semânticos locais.
 
		%Documentos Auto-Explicativos
		
		%Consideramos adequado associar a técnica de template mining com a metodologia proposta por Branting & Lester (1996) para documentos auto-explicativos. Nesta metodologia, os textos são analisados e classificados por sua estrutura retórica. A ligação entre as técnicas se dá pelo aproveitamento das estruturas retóricas como fonte para a definição dos parâmetros dos modelos usados pela técnica de template mining para extração de dados.
 
		%Aquisição de Conhecimento de Textos
		
		%O trabalho publicado pelo Grupo de Engenharia de Conhecimentos de Textos da Universidade de Freiburg através de diversos artigos descreve os esforços para analisar textos que apresentam novas formas de conhecimento. O grupo se utiliza de um parser de LN e almeja a expansão desta base de conhecimento. Da mesma forma que os grupos que tomaram parte dos MUCs, eles também usam técnicas com modelos; entretanto, eles permitem que novos modelos sejam adicionados como resultado da aprendizagem de conceitos (Hahn, & Schnattinger, 1997).

		%O ponto central da pesquisa do grupo trata-se da aquisição de conhecimento de textos que ocorre com a aprendizagem de conceitos que alimenta um sistema de compreensão de linguagem natural. A aprendizagem de conceitos em uma plataforma de compreensão de linguagem natural é orientada para os recursos através do uso de um Machine Readable Dictionary MRD e é orientada por contexto. Os autores alegam que inferir o significado das palavras baseando-se em informações sobre o contexto é mais confiável do que procurar por seu significado em um MRD. A aprendizagem de conceitos é concebida com o desenvolvimento de uma abordagem de aprendizagem de raízes simbólicas. Um exemplo de aquisição de conceito é descrito em Hahn et al. (1996). O projeto do grupo visa duas aplicações práticas de aquisição de conhecimento de textos da língua alemã: artigos sobre testes de produtos de tecnologia de informação (100 documentos com 10^5 palavras) e artigos sobre descobertas médicas (120,000 documentos com $$10^7 palavras).

		%O trabalho descrito por Mauldin (1991) usa a compreensão parcial de textos obtida através de um parser que realiza text skimming para recuperação de informação conceitual, utilizando um banco de dados de scripts que, por sua vez, é alimentado por um método de aprendizagem e um MRD que aprimora o conhecimento léxico. A recuperação de informação executada pelo sistema ferret é referida como recuperação de informação conceitual porque ao invés de realizar a busca através do uso de palavras-chave (baseada em palavras) é usado conhecimento sobre os conceitos.

		%Um ponto de vista interessante sobre o problema de aquisição de conhecimento de textos é descrito em Futrelle & Zhang (1994) que apresenta técnicas de bootstrap que podem descobrir a estrutura de ordem da linguagem natural e definir classes de palavras presentes em corpus de textos. A definição de classes de palavras é baseada no princípio da substituição onde o significado de uma palavra é encontrado pela comparação dos contextos onde as palavras aparecem e onde elas podem ser substituídas por outra palavra da mesma classe. 