\chapter{Extração de Informação} \label{EI}

		Nós, simples seres humanos, não temos a capacidade de processar \textit{megabytes} de texto todos os dias, e nesse mar de bytes, quantas oportunidades deixamos de aproveitar ou informações que estariamos perdendo? Projetos em Processamento de Linguagem Natural originaram a Extração da Informação. Extração de Informação tem como objetivo transformar a coleção de documentos, geralmente com o auxilio de um sistema de Recuperação de Informação, em informação que é facilmente analisada e digerida\cite{Lehnert1996}. Na Extração da Informação, a compreensão do texto fonte não é obrigatória, pois a analise é feita com o objetivo de encontrar porções que contenham o quê deve ser extraido. A sáida de um sistema de Extração da Informação são informações relevantes para o domínio específico em um determinado formato pré-estabelecido de acordo com as orientações iniciais.

%\section{Fundamentos}\label{EI:fundamentos}
		
		A Extração da Informação é uma tarefa mais limitada do que a "compreensão completa do texto". Na Extração da Informação, nós delimitamos o escopo, estabelecendo assim um limite de compreensão, assim, não necessitando analisar o texto completo e seu sentido\cite{Grishman1997}. A Extração da Informação tem um potencial muito grande em extrair dados com maior precisão. Existe um interesse muito grande nas pesquisas em relação a Extração de Informações, uma vez que encontramos uma enorme quantidade de informações em linguagem natural.

		O reconhecimento de palavras, análise de frases, compreensão do sentindo da frase ou de todo o documento são envolvidos nas pesquisas de processamento de linguagens, e aumentam a complexidade no desenvolvimento de um sistema de Extração da Informação.

\section{Extração de Informação não é Recuperação de Informação}\label{EI:EIxRI}

		Recuperação de Informação é uma tecnologia madura que perdura a muito mais tempo do que a Extração da Informação, que começou a poucas décadas. O objetivo da Recuperação de Informação é selecionar documentos relevantes de uma coleção de documentos de acordo com as necessidades do usuario e suas entradas.
		
		O contraste entre os objetivos dos sistemas de Extração da Informação e Recuperação de Informação podem ser descritos como seguem: Recuperação de Informação recupera documentos relevantes de uma coleção, enquanto Extração de Informação extrai informações relevantes de documentos. Consequentemente, as duas tecnicas se complementam, e usadas em combinação podem prover uma ferramenta poderosa[24]\cite{Eikvil1999}.
						
\section{MUC - Message Understanding Conference}\label{EI:MUC}
		
		Observamos dois fatores principais que impulsionaram os estudos em Extração de Informação: o crescimento exponencial de informação conjuntamente com a popularização da internet e um grande alavancador nas pesquisas em Extração da Informação, os congressos \textit{MUC(Message Understanding Conferences)}\cite{Gaizauskas1998}. Eram congressos financiadas pelo \textit{DARPA\footnote{Defense Advanced Research Projects Agency - http://www.darpa.mil/}}, e fora assim batizado por se tratar do processamento de entendimento de mensagens. Surgindo em meados dos anos noventa, ela instaurou métricas e algoritmos estatísticos para auxiliar o governo na avaliação de novos sistemas de Extração de Informação\cite{Sundheim1991}. 
						
		Na avaliação dos MUC, uma descrição detalhada do cenário e quais informações a serem extraidas era dado aos participantes(formados por grupos de pesquisa academicos e particulares), junto com um conjunto de documentos e o modelo a ser extraido dos documentos. Os participantes tinham um tempo limitado\footnote{Geralmente de 1 mês a 6 meses.} para adaptar os sistemas para um novo cenário. Então uma nova coleção de documentos era passado para os participantes, e estes enviavam para os organizadores os resultados extraídos. E assim a avaliação era feita, comparando o gabarito com os resultados extraídos\cite{Appelt1999}.
	
		Podemos observar na tabela~\ref{tab:MUC} as edições e o ano da conferências, bem como as fontes de texto a serem extraidas e os temas(cenario). 
		% Tabela dos MUC
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Conferência} & {\bf Ano} & {\bf Fonte de Texto} & {\bf Tópico(Dominio)} \\
		    \midrule
		    MUC-1 & 1987  & Artigos Militares & Operações de fuga\\
		    MUC-2 & 1989  & Artigos Militares & Operações de fuga\\
		    MUC-3 & 1991  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-4 & 1992  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-5 & 1993  & Artigos de Jornais & Corporate Joint Ventures\\ %Microelectronic production \\		     
		    MUC-6 & 1995  & Artigos de Jornais & Negotiation of Labor Disputes \\%and Corporate management Succession \\
		    MUC-7 & 1997  & Artigos de Jornais & Acidente de aviões \\%lançamento de foguetes \\
		    \bottomrule
		    \end{tabular}
			\caption{MUC}
		  \label{tab:MUC}
		\end{table}
				
		O formato de saída era livre na primeira edição da conferência, da segunda conferência em diante, o formato de saída era determinado pelo cômite organizador. Alguns campos típicos relacionados eram: causa, agente, lugar e tempo de um evento, consequências, etc. Existiam cinco tarefas importantes para a Extração de Informação dentro das \emph{MUC}: Named Entity Recognition, Coreference resolution, template element construction, template relation construction e scenario template production\cite{Chang2006}.

\section{Conceitos Básicos}\label{EI:conceitos}

		Extração de Informação deriva de Processamento de Linguagem Natural e tem como tarefa extrair informações especificas de documentos, muitas vezes encontrado em Linguagem Natural. Muitos sistemas de Extração de Informação seguem sequências de passos como analise léxica, semântica, morfologica, reconhecimento de nomes, entre outras tarefas\cite{Appelt1999}.
		
		A meta de um sistema de Extração de Informação não é entender o texto do documento em si, e sim analisar porções do texto e extrair informações pertinentes. A pertinencia é determinada pelo dominio e cenário, na maioria das vezes, explicitada pelo usuario\cite{Eikvil1999}. A Extração de Informação é útil para quando se tem um conjunto de documentos e existe a necessidade de extrair fatos especificos, como por exemplo, extrair nome de destinos para se viajar em blogs especializados em viagens.  

	\subsection{Abordagens}\label{EI:abordagem}

		Na Extração de Informação, observamos claramente a distinção de duas abordagens\cite{Appelt1999}: \emph{Knowledge Engineering} e \emph{Automatic Training}. 
		
		Em \emph{Knowledge Engineering} o sistema é praticamente construido manualmente pelo \emph{knowledge engineer}\footnote{É a pessoa mais familiarizada com o sistema de Extração de Informação, e conhece melhor o formalismo para expressar as regraspara o sistema.}. Sua construção se baseia no conhecimento que o engenheiro possui  do cenário e dominio com o qual vai se trabalhar. As habilidades do engenheiro que construirá o sistema é crucial para a perfomance da mesma. O processo de desenvolvimento é muito trabalhoso, geralmente, após feito a analise dos documentos e criada e aplicada as regras no sistema, o engenheiro executa o sistema sobre os textos de treino. De acordo com o resultado, ele modifica as regras do sistema e refaz o processo. 
		
		A abordagem de \emph{automatic training} não necessita de um especialista, mas alguém que tenha o conhecimento suficiente do dominio da aplicação. Uma vez que os documentos de \emph{corpus} foram anotados, um algoritmo de treino é executado, treinando o sistema para novos textos. Esta abordagem tem uma resposta mais eficaz, mas depende do conjunto de documentos selecionados para treino. Utilizam métodos estatisticos, e aprendem regras com a interação com o usuario.
		
		Nenhuma das duas abordagens é superior a outra, pois a extração depende de muitas variaveis, e muitas vezes, variaveis externas, logo, não podemos apontar nenhuma abordagem como completa. Ambas utilizadas em conjunto caminha para um sistema ideal.
				
	\subsection{Tipos de Dado}\label{EI:tipo_dado}
		
		A Extração se dá em documentos, e eles são categorizados em três tipos\cite{Eikvil1999}:
		
		\begin{itemize}
          \item \emph{\textbf{Documentos livre/sem estruturação)}} : Texto livre é basicamente o texto onde não encontramos nenhuma forma de estrutura, e é o tipo mais encontrado. Originalmente o objetivo de Extração de Informação era desenvolver sistemas capazes de extrair informações chaves de textos em linguagem natural.   
           
          O estado da arte em Extração da Informação em textos livres muito comumente utiliza tecnicas de Processamento de Linguagens Naturais, e as regras de extração são tipicamente baseada em padrões envolvendo o aspecto sintatico e semântico. A capacidade do homem de processamento ainda é melhor, mas resultados expressivos vem sendo obtidos no processamento em textos sem estrutura. O entendimento de textos sem restrição em Linguagem Natural ainda está longe de ser resolvido por completo, entretando, métodos de Extração de Informação funcionam porque dependem de restrições e padrões que desejamos extrair dos textos\cite{Soderland1999}. 

          \item \emph{\textbf{Documentos semi-estruturados}} : Não são textos totalmente livres de estrutura, mas também as estrutura existente não é tão severa, os textos semi-estruturados encontram-se no intermedio. Técnicas de Processamento de Linguagens Naturais concebem regras para a extração de textos livres, contudo, estas regras funcionam perfeitamente para gramaticas livre de contexto ondem encontramos sentenças inteiras para analisar, fato que nem sempre ocorre em textos semi-estruturados. Regras muito simples utilizadas em textos puramente estruturados não serão eficientes também.
          
          O pesquisador Sergel Abiteboul diferencia dentro do contexto de semi-estruturados, em cinco categorias\cite{Abiteboul1997}\cite{Silveira2001}:
          \begin{itemize}
            \item \textbf{Estrutura Irregular} - Quando uma informação está disposta de mais de uma maneira na estruturação do documento,e.g., o campo de endereço, o qual poderiamos encontrar como uma única \emph{string} representando todo o endereço, ou vários campos como \emph{string} para o nome da rua, um campo de inteiro para o número do logradouro, etc.;
            \item \textbf{Estrutura Implícita} - A estrutura existe, mas não é algo natural e possivelmente necessita de algum processamento, e a representação lógica dos dados não é de imediato obtida. Podemos configurar as paginas em \emph{HTML} nesta categoria, que é puramente texto, mesmo contendo \emph{tags}, não deixa de ser um documento semi-estruturado de puro texto, onde é necessário um processamento de suas \emph{tags} para a obtenção de alguma informação preliminar.;
            \item \textbf{Estrutura Parcial} - Identificamos parte da estrutura de dados, mas a outra parte, muitas vezes não é necessária ou não é passivel de identificação, necessitando uma extração;
            \item \textbf{Estrutura Indicativa} - Existem vários tipos de dados para o mesmo objeto relacionado nas várias instâncias\cite{Silveira2001};
            \item \textbf{Estrutura Flexível} - A instância do objeto consegue assumir outras formas de dados, sendo isso nativo da estrutura em si.
          \end{itemize}
          
          Algumas ferramentas pioneiras em pequisas de dados semi-estruturados na \emph{World Wide Web} foram:  \emph{Yahoo\footnote{Yahoo - http://www.yahoo.com}} e \emph{Altavista\footnote{Altavista - http://www.altavista.com}}. utilizam uma técnica chamada \emph{full text search}, que desconsidera a semântica, comparando o texto completo com as entradas do usuário\cite{Silveira2001}.
            
          Entretanto, como apresenta um minino de estruturação, alguns padrões podem ser construidos, limitando sua utilização na extração. 
          
          \item \emph{\textbf{Documentos estruturados}} : Informações textuais contidas em banco de dados ou qualquer outro gênero de documento com uma estruturação rigida, são a base de textos estruturados. Como seguem uma moldura sem grandes diferenças de um documento para outro, sua informação é facilmente extraida.

        \end{itemize}

	\subsection{Fluxo Geral}\label{EI:fluxo}

		A estrutução de um sistema de Extração de Informação basea-se em alguns passos: Tokenização, Processamento Léxico e Morfológico, Análise Sintatica e Analise do Domínio. O sistema pode possuir apenas algumas das etapas, e não necessariamente deve cobrir todas as etapas para ser um sistema de Extração de Informação. As necessidades da aplicação que implicam quais passos o sistema deve cobrir. Na figura~\ref{fig:EI-estrutura} ilustramos os quatro principais módulos\cite{Appelt1999}.
		
			\begin{figure}[htb]
				\begin{center}				
					\includegraphics[scale=0.5]{./figuras/EI-estrutura.png}				
				\end{center}
				\caption{Principais módulos de um sistema de Extração de Informação}
                \label{fig:EI-estrutura}
			\end{figure}

		Nós podemos dividir o processo de Extração de Informação em duas grandes partes. Primeiramente extraimos \emph{fatos} individuais do texto através de uma analise textual. Então, integramos estes fatos, aumentando os fatos ou criando fatos novos. E por fim, os fatos pertinentes ao cenário, nós transformamos para o formato de saída\cite{Grishman1997}. Para isto, o processo passa por algumas complexidades que se relacionam diretamente com os módulos que utilizaremos.		
		      
		\paragraph{Fatores de complexidade}	Como a Extração de Informação trabalha com textos, enfrentamos dificuldades como a lingua na qual é escrita, o gênero do documento, propriedades e a própria tarefa que efetuaremos sobre o documento\cite{Appelt1999}.
		
			\subparagraph{Idioma} Os documentos se encontram escritos em algum idioma, tão logo nos defrontamos com nossa primeira dificuldade. Algumas linguas necessitam de tratamento morfológico, espaçamento entre palavras e segmentação de palavras.
			
			\subparagraph{Gênero} O gênero do documento com o qual se vai trabalhar influência também. Se limitarmos nossa ferramenta a textos de anúncios de jornais, não é o mesmo que extrairmos informações de artigos cientificos. Como consequencia, o uso da linguagem formal ou informal é extremamente ligada ao documento também.
			
			\subparagraph{Propriedades} Os textos podem conter tabelas, imagens, gráficos entre outros tipos de informação não textual que necessitam de formas especiais de tratamento.
			
			\subparagraph{Tarefas} As tarefas efetuadas pelo sistema também entram na nossa analise de complexidade. Uma ferramenta que apenas procura entidades, possui uma abordagem diferente de uma que procura propriedades a mais de um entidade.
			
		Sistemas de Extração de Informação trabalham com o processamento de muitos documentos e um espaço muito curto de tempo. Então, para não prejudicar o desempenho, utiliza-se maquinas de estado finito em abundância. O alvo da extração de uma Extração de Informação pode ser uma relação de \emph{n-tuplas} ou muito mais complexa considerando a hierarquia e organização dos dados. 
		
		Programas que realizam a tarefa de Extração de Informação são usualmente chamados de \emph{extratores} ou \emph{wrappers}. Um \emph{wrapper} geralmente executa a tarefa de encontrar padrões, e estes dependem de um conjunto de regras. Adaptar um sistema de Extração de Informação tem muitos pontos a serem observados: tipo de texto, domínio, cenário, conjunto de regras\cite{Chang2006}.
						
		%\paragraph{Analise Morfológica} 
		Muitos sistemas de Extração de Informação são construídos em cima da língua inglesa, que não necessita uma análise morfológica muito aprofundada onde uma lista com as variações das palavras seria o suficiente. O idioma alemão por sua vez, é essencial fazer uma análise morfológica, pois é composto por palavras aglutinadas\cite{Appelt1999}. 
						
		%\paragraph{Análise Lexica}		
		A maior parte da analise do texto é feita através de um conjunto de expressões regulares. Se a expressão encontrada estiver inserida no conjunto de expressões regulares, tão logo ela receberá um marcador, e dependendo do sistema, outros recursos\cite{Grishman1997}.
		
		O Reconhecimento de Nomes em um texto é uma tarefa de destaque, uma vez que nomes aparecem frequentemente em todos os tipos de texto, e de muitas maneiras. Os nomes aparecem em um conjunto de padrão, podendo conter prefixo ou sufixo, estar escrito com letras maíusculas, facilitando assim sua extração. Observando a tabela~\ref{tab:exemplos_nome}, temos algumas maneiras de como o nome João José da Silva Pereira Junior pode aparecer em um texto.

		% Tabela com exemplos de aparição de nomes
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Exemplos de aparição de nomes} \\
		    \midrule
		    João José da Silva Pereira Junior \\ 
		    João José da Silva Pereira Jr. \\
		    João J. da Silva Pereira Jr. \\
		    João J. S. P. Jr.\\
		    Sr. João Pereira Jr. \\
		    JOÃO JOSÉ DA SILVA PEREIRA JUNIOR \\
		    JUNIOR, João J. S. P.		    
		    \bottomrule
		    \end{tabular}
			\caption{Exemplos de aparição de nomes}
		  \label{tab:exemplos_nome}
		\end{table}

		Alguns sistemas não tem fases distintas para léxica e sintatica, outros implementam um \emph{parser} para a sentença inteira. Em geral, os sistemas utilizam partes que possuem certeza sobre sua construção, tanto sintaticamente quanto semânticamente. Na analise sintática, podemos ainda ter muitas interpretações ambíguas, para tal, a semântica e o domínio especifico da aplicação eliminam outras interpretações do dados extraídos.
		
		Construir uma estrutura completa de analise sintática é extremamente dificil. Algumas decisões são particularmente difíceis e dependem do contexto. \emph{Parsers} que buscam avaliar sentenças inteiras pecam no aspecto das decisões locais. Se as relações sintaticas forem corretamente para o passo seguinte da analise, a interpretação dos modelos de cenário serão mais simples e corretas.
		

\section{Avaliação}\label{EI:avaliacao} 
		
		Os critérios de avaliação consistem em: quanta informação foi extraída(\textit{recall}), quanto da informação extraída é correta(\textit{precision}) e quanto da informação extraída é supérflua(\textit{overgeneration})\cite{Sundheim1991}. As conferência \textit{MUC} têm um papel fundamental na definição dessas medidas, na necessidade de avaliar os sistemas de Extração de Informação. Inicialmente as medidas de precisão e cobertura foram herdadas do sistema de avaliação de Recuperação de Informação. Como as técnicas de Extração e Recuperação são distintas, os nomes foram mantidos, porém as definições das medidas foram alteradas\cite{Gaizauskas1998}.
		 
		\begin{itemize}
          	\item \textbf{Cobertura ou Abrangência}(\textit{Recall}) : Quanto da informação extraída é relevante. Ou seja, é medida através da informação corretamente extraída($N_{extraido-correto}$) sobre a informação relevante na página($N_{total-extraidos}$). Representada pela fórmula~\ref{formula:cobertura}
          	
          	\begin{equation}\label{formula:cobertura}
              Cobertura = \frac{N_{extraido-correto}}{N_{total-extraidos}}              
            \end{equation}            
    	
          	\item \textbf{Precisão}(\textit{Precision}) : Quanto da informação extraída é correta. É obtida através da informação corretamente extraída($N_{extraido-corretos}$) sobre a informações extraídas ($N_{resposta}$).
          	
          	\begin{equation}\label{formula:precisao}
              Precis\~{a}o = \frac{N_{extraido-correto}}{N_{resposta}}
            \end{equation}
						
			Importante ressaltar que $N_{total-extraido}$ e $N_{resposta}$ são inversamente proporcionais, isto é, quando a \emph{Cobertura} aumenta, a \emph{Precisão} tende a diminuir e vice-cersa. \emph{Precisão} e \emph{Cobertura} estão sempre no intervalo de $[0, 1]$, sendo 0 o pior resultado e 1 o melhor.
			  
  		 	\item \textbf{\textit{F-measure}} : A \textit{F-measure} mede considerando a precisão e a cobertura. O parâmetro $\beta$ quantifica a preferência da cobertura sobre a precisão. 
  		 	
  		 	\begin{equation}\label{formula:F-measure}
              F-measure = \frac{(\beta^2 + 1)*Cobertura*Precisão}{\beta^2 * (Cobertura + Precisão)}
            \end{equation}

			Geralmente utilizamos $\beta = 1$ , balanceando assim as duas medidas, e aplicando na fórmula~\ref{formula:F-measure} temos:
			 
  		 	\begin{equation}\label{formula:F1}
              F_1 = \frac{2*Cobertura*Precisão}{(Cobertura + Precisão)}
            \end{equation}			   
  		 		 
        \end{itemize} 
		 
		Para ilustrar melhor os cálculos, utilizando a ferramenta \emph{NameParser} criada para o projeto \textit{Salus Cyted}, que será discutida no capitulo~\ref{Capitulo 5}. A ferramenta será aplicada na página  \textit{Association Alzheimer\footnote{Association Alzheimer - http://www.alz.org/}}, vista na figura~\ref{fig:siteAssociationAlzheimer} como nossa fonte de dados. 
		
			\begin{figure}[htb]
				\begin{center}				
					\includegraphics[scale=0.35]{./figuras/site_nome_grifado.png}				
				\end{center}
                \label{fig:siteAssociationAlzheimer}
			\end{figure}

		Temos como resultante a tabela ~\ref{tab:resultados_alzheimerassociation}.
				
            \begin{table}[htbp]
              \centering              
                    \begin{tabular}{rr}
                        \addlinespace
                        \toprule
                              & Página \\
                        \midrule                              
                                Nomes presentes & 16 \\
                                Nomes identificados pelo programa (usando expressões) & 83 \\
                                Nomes corretamente identificados (usando expressões) & 16 \\
                                Precisão – Precision & 100\% \\
                                Cobertura(Abrangência) – Recall & 19\% \\                              
                        \bottomrule
                    \end{tabular}
                \caption{Resultados da extração}
              \label{tab:resultados_alzheimerassociation}
            \end{table}

        Interpretando os dados, nossa precisão é altíssima conseguindo obter todos os nomes presentes na página, porém extraímos muitas outras informações irrelevantes. Aplicando a $F_1$, temos um aproveitamento de 31\%, um resultado animador mas muito longe do ideal esperado.
        
        Devemos lembrar também que o domínio atribuido ao resultado é muito importante, por exemplo, se encontrarmos um nome pela metade, devemos considerá-lo errado ou correto? Quando o nome se repete ao longo do página, devemos conta-lo apenas uma vez ou mais vezes? Questões assim dificultam o critério e devem ser relevadas para uma melhor interpretação dos dados.
        
				
		%Extração de Informação baseada em conhecimento 
		
		%O papel de padrões lingüísticos é sustentar a interpretação de textos na Extração de Informação baseada em conhecimento. Em função da construção de padrões lingüísticos ser um gargalo mesmo em domínios limitados, propôs-se o uso de um mecanismo de aprendizagem indutivo para construir automaticamente uma base de conhecimento de padrões. O sistema automático é construído sempre que se identifica um padrão lingüístico desconhecido. Um pressuposto importante embasando esta pesquisa é o reduzido número de expressões normalmente utilizado para descrever uma informação dentro de um domínio limitado (Kim & Moldovan, 1995).
 
		%Template Mining
		
		%Template Mining ou mineração por modelos é uma técnica de processamento de LN que extrai dados de textos que possuem padrões que permitam o reconhecimento do que se deseja extrair ou de seus arredores. Um modelo contém informação sobre o que procurar no texto e é disparado a extrair determinadas partes devidamente indicadas. Lawson et al., (1996) descreve aplicações de template mining em domínios restritos alegando que esta técnica é própria para áreas cujos textos são claros com frases objetivas e de natureza declarativa.
 
		%Text windowing
		
		%A técnica text windowing é do tipo orientada para corpus de textos que avalia palavras na busca de blocos de palavras que estejam relacionadas por sintática ou propriedades léxicas. Jacquemin (1996), descreve uma aplicação de text windowing em um método para selecionar trechos de textos motivados por propriedades léxicas, combinando informação conceitual em listas de termos com metaregras em filtros semânticos locais.
 
		%Documentos Auto-Explicativos
		
		%Consideramos adequado associar a técnica de template mining com a metodologia proposta por Branting & Lester (1996) para documentos auto-explicativos. Nesta metodologia, os textos são analisados e classificados por sua estrutura retórica. A ligação entre as técnicas se dá pelo aproveitamento das estruturas retóricas como fonte para a definição dos parâmetros dos modelos usados pela técnica de template mining para extração de dados.
 
		%Aquisição de Conhecimento de Textos
		
		%O trabalho publicado pelo Grupo de Engenharia de Conhecimentos de Textos da Universidade de Freiburg através de diversos artigos descreve os esforços para analisar textos que apresentam novas formas de conhecimento. O grupo se utiliza de um parser de LN e almeja a expansão desta base de conhecimento. Da mesma forma que os grupos que tomaram parte dos MUCs, eles também usam técnicas com modelos; entretanto, eles permitem que novos modelos sejam adicionados como resultado da aprendizagem de conceitos (Hahn, & Schnattinger, 1997).

		%O ponto central da pesquisa do grupo trata-se da aquisição de conhecimento de textos que ocorre com a aprendizagem de conceitos que alimenta um sistema de compreensão de linguagem natural. A aprendizagem de conceitos em uma plataforma de compreensão de linguagem natural é orientada para os recursos através do uso de um Machine Readable Dictionary MRD e é orientada por contexto. Os autores alegam que inferir o significado das palavras baseando-se em informações sobre o contexto é mais confiável do que procurar por seu significado em um MRD. A aprendizagem de conceitos é concebida com o desenvolvimento de uma abordagem de aprendizagem de raízes simbólicas. Um exemplo de aquisição de conceito é descrito em Hahn et al. (1996). O projeto do grupo visa duas aplicações práticas de aquisição de conhecimento de textos da língua alemã: artigos sobre testes de produtos de tecnologia de informação (100 documentos com 10^5 palavras) e artigos sobre descobertas médicas (120,000 documentos com $$10^7 palavras).

		%O trabalho descrito por Mauldin (1991) usa a compreensão parcial de textos obtida através de um parser que realiza text skimming para recuperação de informação conceitual, utilizando um banco de dados de scripts que, por sua vez, é alimentado por um método de aprendizagem e um MRD que aprimora o conhecimento léxico. A recuperação de informação executada pelo sistema ferret é referida como recuperação de informação conceitual porque ao invés de realizar a busca através do uso de palavras-chave (baseada em palavras) é usado conhecimento sobre os conceitos.

		%Um ponto de vista interessante sobre o problema de aquisição de conhecimento de textos é descrito em Futrelle & Zhang (1994) que apresenta técnicas de bootstrap que podem descobrir a estrutura de ordem da linguagem natural e definir classes de palavras presentes em corpus de textos. A definição de classes de palavras é baseada no princípio da substituição onde o significado de uma palavra é encontrado pela comparação dos contextos onde as palavras aparecem e onde elas podem ser substituídas por outra palavra da mesma classe. 