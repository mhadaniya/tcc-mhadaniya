\chapter{Recuperação de Informação} \label{RI}

		Recuperação de Informação (RI) é a tarefa de encontrar documentos relevantes a partir de um \textit{corpus} ou conjunto de textos em resposta a uma necessidade de informação de um usuário \cite{Smeaton1997}. Um dos maiores problemas enfrentados desde seu início, e que perpetua atualmente é a informação estar contida em linguagem natural. Quando a \emph{WWW} foi concebida, a comunidade acadêmica que tratava de RI concentraram suas atenções para uma melhoria dos motores de busca, voltando a impulsionar o crescimento da RI.
				 		
		RI possui limites bem delimitados, e qualquer tarefa além de prover ao usuário os documentos, não é um sistema de recuperação de informação. A tecnologia de RI é quase sempre encontrada no núcleo de funcionalidades dos sistemas de busca de informações de uma maneira imperceptível para o usuário. Técnicas como: filtragem, roteamento, categorização e clusterização  possuem em comum a busca e comparação dos documentos e as necessidades do usuário \cite{Smeaton1997}.
		
		\begin{itemize}
		  \item filtragem - através do fluxo de documentos entre um certo perfil ou grupo de usuários, refletindo a informação desejada;
		  \item categorização - é a tarefa de categorizar o documento em um conjunto pré-definido de categorias;
		  \item roteamento - divide a entrada de documentos para grupos ou usuários baseado no conteúdo;
		  \item clusterização - é o agrupamento de documentos semelhantes para posterior busca ou outra utilização;
		\end{itemize}		
				
		%Resumidamente a operação de um sistema de RI ocorre com o usuário descrevendo suas necessidades para o sistema, então o sistema retorna os documentos que correspondem. Smeaton \cite{Smeaton1997} sugere algumas métricas heurísticas\footnote{Os estudos abordados quanto aos modelos matemáticos descritos pelo autor foram no âmbito superficial.} para tal ordenamento  e enumera áreas onde a pesquisa de RI são bem ativas.
		
%		A operação de recuperação em sistemas de RI objetiva computar graus de coincidência entre a consulta do usuário e os documentos para ordenar cada documento. Smeaton \cite{Smeaton1997} sugere algumas métricas heurísticas para tal ordenamento  e enumera áreas onde a pesquisa de RI são bem ativas tais como a recuperação baseada em \emph{clusters}, a recuperação pela combinação de diversas estratégias, indexação semântica latente, recuperação de passagem e documentos de comprimento heterogêneo.
				
		Sistemas de RI são estruturados através da definição da fonte de informação com a qual se trabalha, ou seja, os tipos de documentos que serão indexados. Posteriormente, as operações que serão executadas no momento das buscas devem ser determinadas, estruturando os documentos de acordo com as tarefas a serem executadas. Em seguida, um índice com os termos contidos nos documentos é criado \cite{Baeza-Yates1999}. Com uma consulta, o usuário descreve suas necessidades através de termos e o processo de RI é iniciado \cite{Beppler2008}.
		
		A operação de recuperação em sistemas de RI objetiva computar graus de coincidência entre a consulta do usuário e os documentos para ordenar cada documento. Smeaton \cite{Smeaton1997} sugere algumas métricas heurísticas para tal ordenamento  e enumera áreas onde a pesquisa de RI são bem ativas. 
		
		O problema da aquisição de conhecimento de textos vêm sendo questionado pela comunidade de RI em função da rápida pulverização de informação impulsionada pela \emph{Internet}. A pesquisa sobre atividades baseadas em \emph{corpus} de textos têm sido encorajada, facilitando o desenvolvimento de soluções.
		
%		Motivado pela forte interdependência entre a RI e o processamento de linguagem natural, Smeaton (1995, 1995a, 1995b) questiona a real utilidade do processamento de linguagem e dos demais recursos lingüísticos para a RI. O autor alega que o processamento de linguagem natural oferece um auxílio modesto para a eficiência da RI pelo fato das técnicas de processamento de LN terem sido desenvolvidas visando aplicações de tradução automática e interfaces de linguagem natural. Uma característica que limita a ajuda oferecida pelas técnicas de processamento de LN oriunda-se na complexidade destas técnicas tornando-as eficientes apenas quando aplicadas sobre uma pequena quantidade de textos. Uma solução para este problema é proposta em Zhai (1997) que apresenta um método para indexação de documentos testado num conjunto de documentos de 250 mega bytes. Neste método, o autor propõe um modelo probabilístico para realizar um parsing de expressões ao invés da indexação por palavras, demonstrando uma significativa melhora na recuperação.

%		Outras técnicas além das baseadas em linguagem natural também podem beneficiar a tecnologia de RI. O método relevance feedback (Haines e Croft, 1993) aprimora a qualidade da recuperação de informação inteligente ao modificar a consulta baseando-se na retroalimentação do usuário. A consulta é modificada através de uma modificação nos pesos que caracterizam seus termos motivada pela informação dada pelo usuário. O método relevance feedback é proposto em Haines e Croft (1993) como um aprimoramento do modelo de recuperação que utiliza Redes de Inferência (Turtle, 1991). Redes de inferência são um modelo de recuperação de informação baseado em probabilidade para raciocínio com incerteza. A rede de inferência é um grafo com quatro tipos diferentes de nós: para documentos, para a representação conceitual do conteúdo dos documentos, para as consultas, e o último para a informação desconhecida. A cada nova consulta, os nós são instanciados para cada documento do conjunto e as probabilidades são propagadas para inferir uma probabilidade associada à informação desconhecida; gerando, assim, um ordenamento dos documentos.

%		Uma aplicação do método de redes de inferência na recuperação de informação é o sistema de recuperação (Callan, Croft, e Harding, 1992) que vem sendo implementado com sucesso sobre uma base de 1 giga byte. O sistema INQUERY contém um subsistema de parsing que comporta uma indexação sofisticada e uma complexa formulação nas consultas.

%		O método de relevance feedback do sistema INQUERY foi utilizado por Daniels & Rissland (1995) em uma pesquisa que também ressalta a importância do uso do paradigma de RBC na recuperação da informação. As autoras propõem um sistema híbrido de RBC-RI que realiza a busca por documentos similares em uma pequena base de conhecimento de casos em função das fortes necessidades de representação de conhecimento que ofereceria uma base maior. O resultado gerado pelo sistema baseado em casos é um conjunto de textos que sugerem uma lista de termos que é usada para definir uma consulta que conduz a recuperação de documentos baseada em textos.
  
  	\section{Modelos de Recuperação de Informação}\label{RI:Modelos}
  	
%  		De acordo com Baeza-Yates e Ribeiro-Neto \cite{Baeza-Yates1999}, podemos decompor um modelo de RI em \cite{Beppler2008}:
%  		\begin{itemize}
%  		  \item um conjunto de visões lógicas de documentos de uma coleção - é a forma como o documento é indexado, e.g., palavras-chaves;
%  		  \item um conjunto de visões lógicas da informação prestada pelo usuário;
%  		  \item um framework para modelar documentos, consultas e suas relações - tecnologia utilizada para prover as ;
%  		  \item uma função de ordenação - função de ordenação escolhida para retornar os resultados.
%  		\end{itemize}
  		
  		Greengrass \cite{Greengrass2000} propõem duas categorias para os modelos de RI: semânticos e estátisticos. Os semânticos tem a preocupação de ``entender'' um texto em linguagem natural. Quanto aos modelos estátisticos, são atribuidos medidas estatísticas mensurando a comparação entre uma consulta e um documento. Na categoria estátistica enquandramos os modelos: Booleano, Booleano Estendido, Vetorial, Probabilístico, Difuso e Indexação Semântica Latente. O modelo de Processamento de Linguagem Natural representa a categoria semântica. 
  	
  	\subsection{Modelo Booleano}
  	  		
  		Utilizando-se da teoria dos conjuntos e álgebra booleana, as consultas são construidas através de expressões booleanas e conectores lógicos: AND, OR, NOT. A recuperação de um determinado documento só é efetuada mediante um valor verdadeiro das expressões, no nosso caso, uma consulta. Devido a simplicidade e ao formalismo, temos um resultado não ordenado, acarretando também à recuperação de muitos ou poucos documentos \cite{Baeza-Yates1999}.
  		
  	\subsection{Modelo Booleano Estendido}
  	
  		Este modelo é proposto com algumas melhorias em relação seu predescessor, implementando uma função de ordenação e a utilização de diferentes operadores. Este modelo atribui valores no intervalo $[0,1]$, que equivale ao grau de comparação de uma expressão com um documento \cite{Lee1994}.
  	
  	\subsection{Modelo Vetorial}
  	
  		Este modelo é representado por um vetor ou uma lista de termos ordenados. O grau de similaridade de um documento em relação a uma consulta é a avaliação entre os vetores que representam o documento e a consulta. Com isto, uma ordenação de acordo com o grau de similaridade é executada dada uma consulta \cite{Baeza-Yates1999}.
  		
  	\subsection{Modelo Probabilístico}
  	
  		Fazendo-se uso de cálculos probabilísticos, o modelo calcula a probabilidade condicional em que um determinado documento é relevante a uma dada consulta. Consulta e documentos são representados por meio de um conjunto de termos, calculando-se a probabilidade de ocorrência dos termos de uma consulta em documentos relevante e não-relevantes. A função probabilistica depende do modelo a ser usado, bem como os termos estão distribuidos entre os documentos \cite{Greengrass2000}.
  		
	\subsection{Modelo Difuso}
	
		É um modelo extendido do modelo booleano e possui uma função de ordenação cujo resultado da comparação entre um documento e uma consulta é aproximado. Como Zadeh redefiniu o intervalo fechado do conceito clássico da pertinência de $[0,1]\in\mathbb{Z}$ para o intervalo contínuo $[0,1]\in\mathbb{R}$ \cite{Baeza-Yates1999}. 
		
		A aproximação considera que cada termo de uma consulta define um conjunto difuso e cada documento possui um grau de participação nesse conjunto. Muitas críticas são lançadas a este modelo por gerar medidas incorretas \cite{Lee1994}.
		
		A principal justificativa para o método difuso é a falta de informação frequente do usuário e do próprio sistema em saber se o documento possui a informação consultada ou não \cite{Lee1994}.

	\subsection{Modelo de Indexação Semântica Latente}
	
		A indexação semântica latente (LSI) é uma técnica automática que analisa as co-ocorências de termos em documentos textuais almejando descobrir relacionamentos entre eles.
		
		LSI é um modelo que consome processamento devido as estruturas escolhidas para a analise dos textos, no caso, uma matriz esparsa termo-documento. Utilizando a Decomposição de Valores Singulares (SVD), a matriz é decomposta em outras três matrizes. 
		
		Este é um modelo que visa a captura de termos e suas dependências que podem ter um significado semântico.
		  	
  	\subsection{Modelo de Processamento de Linguagem Natural}
  	
  		O modelo que usa processamento em linguagem natural pode ser categorizado como modelo semântico, porque a estrutura e o significado dos documentos estão intimamente ligados ao modelo. Raramente são utilizadas em RI, mas geralmente são empregadas em conjunto com outros modelos estatísticos \cite{Greengrass2000}.
  		
  		Smeaton \cite{Smeaton1997} defende que as técnicas de processamento de linguagem natural adotadas na RI apenas auxiliam eficientemente quando utilizadas em pequenas quantidades de textos. Assim sendo, a complexidade de técnicas de PLN é oriunda das aplicações para a qual fora desenvolvida como tradução automática e interfaces de linguagem natural.
  		 
  		%Motivado pela forte interdependência entre a RI e o processamento de linguagem natural, Smeaton (1995, 1995a, 1995b) questiona a real utilidade do processamento de linguagem e dos demais recursos lingüísticos para a RI. O autor alega que o processamento de linguagem natural oferece um auxílio modesto para a eficiência da RI pelo fato das técnicas de processamento de LN terem sido desenvolvidas visando aplicações de tradução automática e interfaces de linguagem natural. Uma característica que limita a ajuda oferecida pelas técnicas de processamento de LN oriunda-se na complexidade destas técnicas tornando-as eficientes apenas quando aplicadas sobre uma pequena quantidade de textos. Uma solução para este problema é proposta em Zhai (1997) que apresenta um método para indexação de documentos testado num conjunto de documentos de 250 mega bytes. Neste método, o autor propõe um modelo probabilístico para realizar um parsing de expressões ao invés da indexação por palavras, demonstrando uma significativa melhora na recuperação.
  		
  	
  	\section{Recuperação de Informação na WEB}\label{RI:webRI}			

		Quando estamos lidando com a \emph{Web} temos um cenário que contrasta com a chamada RI Clássica. Na RI Clássica temos um domínio e usuários definidos, quando na \emph{Web} encontramos um cenário dinâmico e usuários consultando simultaneamente as informações \cite{Kobayashi1999}. 
		
		Muitas características devem ser levadas em conta quando estamos recuperando documentos na \emph{WEB} \cite{Huang2000}:
		
		\begin{itemize}
          \item \textbf{Tamanho da Internet} - O tamanho da \emph{Internet}, segundo Zhang e seu grupo de pesquisa \cite{Zhang2008}, estima-se que em Janeiro de 2008 a Internet continha 62400000 hostnames ativos. De acordo com a pesquisa, a Lei de Moore\footnote{A Lei de Moore foi predita por um dos fundadores da Intel, Gordon Moore, e sugere que a cada dezoito meses a capacidade de transitores no CPU dobra. Apareceu em 1965 e se manteve como verdade por quase meio século, e costuma ser utilizada para prever modelos futuros de tecnologias.} é observada, exceto que para a Internet, foi visto que a cada cinco anos, ela dobra de tamanho. Importante esclarecer que os dados do tamanho da \emph{Internet} vária de acordo com grupos de pesquisa, mas todos chegam a resultados similares quanto ao crescimento exponencial;
          \item \textbf{Dinamismo da Internet} - As técnicas de Recuperação de Informação são geralmenta estática, enquanto a \emph{Web} está em constante metamorfose;
          \item \textbf{Duplicação} - 30\% do contéudo da \emph{Internet} é uma cópia de algum conteúdo existente;
          \item \textbf{Comportamentos específicos} - É estimado que 85\% dos usuários utilizam apenas a primeira página retornada das \emph{search engines}, e 28\% modificam sua consulta original;
          \item \textbf{Multiplos tipos de usuário} - Possui muitos tipos de usuários e cada usuário utiliza a \emph{Internet} para uma tarefa específica;
          \item \textbf{Idiomas} - Como a \emph{Internet} se tornou algo mundial, as páginas são encontradas em mais de 100 idiomas; 
          \item \textbf{Alta Linkagem (\emph{High Linkage})} - Cada página contém aproximadamente oito links para outras páginas;          
        \end{itemize}
        
        Com estas características, podemos ter uma noção da dificuldade do campo de RI na \emph{Web}. Se considerarmos a \emph{Web} como uma grande base de dados, não temos uma aplicação efetiva das tarefa da RI Clássica de indexar, categorizar, organizar ou clusterizar, e as \emph{queries} de busca de usuários distintos para uma mesma informação apresentam diferenças enormes.
        
%        \subsection{Indexação}
        
%		O conceito de indexação em RI é o ato de atribuir índices para documentos, os quais serão utilizados para recuperação posteriormente \cite{Korfhage1998}. Destacamos quatro formas de indexação: indexação manual, indexação automática, indexação baseada em agentes inteligentes e indexação de metadados.
		
%		A indexação manual
        
		        