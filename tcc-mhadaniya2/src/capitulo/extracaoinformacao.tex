%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Trabalho de Conclusão de Curso
% Aluno: Mario Henrique A. C. Adaniya
% Orientador: Prof. Dr. Mario Lemos Proença Jr.
% Curso: Ciência da Computação - Universidade Estadual de Londrina
% 
%  Capitulo sobre Extração de Informação
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Extração de Informação} \label{EI}

\sigla{EI}{Extração de Informação}
\sigla{HTML}{Hypertext Markup Language}
\sigla{KDD}{Knowledge Discovery Database}
\sigla{MUC}{Message Understading Conference}
\sigla{OWL}{Web Ontology Language } 
\sigla{PLN}{Processamento de Linguagem Natural}
\sigla{RDF}{Resource Description Framework}
\sigla{RI}{Recuperação de Informação}
\sigla{XML}{Extensible Markup Language}
\sigla{URI}{Uniform Resource Identifier}
\sigla{WB}{Web Mining}
\sigla{WWW}{World Wide Web}
\sigla{W3C}{World Wide Web Consortium}

		Não temos a capacidade de processar \emph{megabytes} de texto todos os dias, e nesse volume de bytes, quantas oportunidades deixamos de aproveitar ou informações que estaríamos perdendo? Projetos em Processamento de Linguagem Natural(PLN) originaram a Extração da Informação. EI tem como objetivo transformar a coleção de documentos, geralmente com o auxílio de um sistema de Recuperação de Informação, em informação que é facilmente analisada e digerida \cite{Lehnert1996}. Na EI, a compreensão do texto fonte não é obrigatória, pois a análise é feita com o objetivo de encontrar porções que contenham o quê deve ser extraído. A sáida de um sistema de Extração da Informação são informações relevantes para o domínio específico em um determinado formato pré-estabelecido de acordo com as orientações iniciais.
		
		A Extração da Informação é uma tarefa mais limitada do que a ``compreensão completa do texto''. Na Extração da Informação, nós delimitamos o escopo, estabelecendo assim um limite de compreensão, assim, não necessitando analisar o texto completo e seu sentido \cite{Grishman1997}. A Extração da Informação tem um potencial muito grande em extrair dados com maior precisão, existindo um interesse muito grande nas pesquisas, uma vez que encontramos uma enorme quantidade de informações em linguagem natural.

		O reconhecimento de palavras, análise de frases, compreensão do sentindo da frase ou de todo o documento são envolvidos nas pesquisas de processamento de linguagens, e aumentam a complexidade no desenvolvimento de um sistema de Extração da Informação.

\section{Extração de Informação não é Recuperação de Informação}\label{EI:EIxRI}

		Recuperação de Informação é uma tecnologia madura que perdura há muito mais tempo do que a Extração da Informação, que começou a poucas décadas. O objetivo da Recuperação de Informação é selecionar documentos relevantes de uma coleção de documentos de acordo com as necessidades do usuário e suas entradas.
		
		O contraste entre os objetivos dos sistemas de Extração da Informação e Recuperação de Informação podem ser descritos como seguem: Recuperação de Informação recupera documentos relevantes de uma coleção, enquanto Extração de Informação extrai informações relevantes de documentos. Consequentemente, as duas técnicas se complementam, e usadas em combinação podem prover uma ferramenta poderosa \cite{Eikvil1999}.
						
\section{MUC - Message Understanding Conference}\label{EI:MUC}
		
		Observamos dois fatores principais que impulsionaram os estudos em EI: o crescimento exponencial de informação conjuntamente com a popularização da internet e um grande alavancador nas pesquisas em EI, os congressos \textit{MUC(Message Understanding Conferences)} \cite{Gaizauskas1998}. Eram congressos financiadas pelo \textit{DARPA\footnote{Defense Advanced Research Projects Agency - http://www.darpa.mil/}}, e foram assim batizados por tratar-se do processamento de entendimento de mensagens. Surgindo em meados dos anos noventa, ela instaurou métricas e algoritmos estatísticos para auxiliar o governo americano na avaliação de novos sistemas de Extração de Informação \cite{Sundheim1991}. 
						
		Na avaliação dos MUC, uma descrição detalhada do cenário e quais informações a serem extraidas era dado aos participantes(formados por grupos de pesquisa academicos e particulares), junto com um conjunto de documentos e o modelo a ser extraido dos documentos. Os participantes tinham um tempo limitado\footnote{Geralmente de 1 mês a 6 meses.} para adaptar os sistemas para um novo cenário. Então uma nova coleção de documentos era passado para os participantes, e estes enviavam para os organizadores os resultados extraídos. E assim a avaliação era feita, comparando o gabarito com os resultados extraídos \cite{Appelt1999}.
	
		Podemos observar na tabela~\ref{tab:MUC} as edições e o ano da conferências, bem como as fontes de texto a serem extraidas e os temas(cenario). 
		% Tabela dos MUC
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Conferência} & {\bf Ano} & {\bf Fonte de Texto} & {\bf Tópico(Dominio)} \\
		    \midrule
		    MUC-1 & 1987  & Artigos Militares & Operações de fuga\\
		    MUC-2 & 1989  & Artigos Militares & Operações de fuga\\
		    MUC-3 & 1991  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-4 & 1992  & Artigos de Jornais & Atividades Terroristas na América Latina \\
		    MUC-5 & 1993  & Artigos de Jornais & Corporate Joint Ventures\\ %Microelectronic production \\		     
		    MUC-6 & 1995  & Artigos de Jornais & Negotiation of Labor Disputes \\%and Corporate management Succession \\
		    MUC-7 & 1997  & Artigos de Jornais & Acidente de aviões \\%lançamento de foguetes \\
		    \bottomrule
		    \end{tabular}
			\caption{MUC}
		  \label{tab:MUC}
		\end{table}
				
		O formato de saída era livre na primeira edição da conferência, da segunda conferência em diante, o formato de saída era determinado pelo cômite organizador. Alguns campos típicos relacionados eram: causa, agente, lugar e tempo de um evento, consequências, etc. Existiam cinco tarefas importantes para a Extração de Informação dentro das MUC: \textit{Named Entity Recognition, Coreference Resolution, Remplate Element Construction, Template Relation Construction e Scenario Template Production} \cite{Chang2006}.

\section{Conceitos Básicos}\label{EI:conceitos}

		Extração de Informação deriva de Processamento de Linguagem Natural e tem como tarefa extrair informações especificas de documentos, muitas vezes encontrado em Linguagem Natural. Muitos sistemas de Extração de Informação seguem sequências de passos como analise léxica, semântica, morfologica, reconhecimento de nomes, entre outras tarefas \cite{Appelt1999}.
		
		A meta de um sistema de Extração de Informação não é entender o texto do documento em si, e sim analisar porções do texto e extrair informações pertinentes. A pertinencia é determinada pelo domínio e cenário, na maioria das vezes, explicitada pelo usuário \cite{Eikvil1999}. A Extração de Informação é útil para quando se tem um conjunto de documentos e existe a necessidade de extrair fatos específicos, como por exemplo, extrair nome de destinos para se viajar em blogs especializados em viagens.  

	\subsection{Abordagens}\label{EI:abordagem}

		Na Extração de Informação, observamos claramente a distinção de duas abordagens \cite{Appelt1999}: \emph{Knowledge Engineering} e \emph{Automatic Training}. 
		
		Em \emph{Knowledge Engineering} o sistema é praticamente construido manualmente pelo \emph{knowledge engineer}\footnote{É a pessoa mais familiarizada com o sistema de Extração de Informação, e conhece melhor o formalismo para expressar as regras para o sistema.}. Sua construção se baseia no conhecimento que o engenheiro possui  do cenário e domínio com o qual vai se trabalhar. As habilidades do engenheiro que construirá o sistema é crucial para a perfomance da mesma. O processo de desenvolvimento é muito trabalhoso, geralmente, após feito a analise dos documentos e criada e aplicada as regras no sistema, o engenheiro executa o sistema sobre os textos de treino. De acordo com o resultado, ele modifica as regras do sistema e refaz o processo. 
		
		A abordagem de \emph{automatic training} não necessita de um especialista, mas alguém que tenha o conhecimento suficiente do domínio da aplicação. Uma vez que um conjunto de documentos foram anotados, um algoritmo de treino é executado, treinando o sistema para novos textos. Esta abordagem tem uma resposta mais eficaz, mas depende do conjunto de documentos selecionados para treino. Utilizam métodos estatísticos, e aprendem regras com a interação com o usuário.
		
		Nenhuma das duas abordagens é superior a outra, pois a extração depende de muitas variaveis, e muitas vezes, variaveis externas, logo, não podemos apontar nenhuma abordagem como completa. Ambas utilizadas em conjunto caminha para um sistema ideal.
				
	\subsection{Tipos de Dado}\label{EI:tipo_dado}
		
		A Extração de Informação se dá em documentos, e eles são categorizados em três tipos \cite{Eikvil1999}:
		
		\begin{itemize}
          \item[I.] \emph{\textbf{Documentos livre/sem estruturação}} : Texto livre é basicamente o texto onde não encontramos nenhuma forma de estrutura, e é o tipo mais encontrado. Originalmente o objetivo de EI era desenvolver sistemas capazes de extrair informações chaves de textos em linguagem natural.   
           
          O estado da arte em Extração da Informação em textos livres muito comumente utiliza técnicas de Processamento de Linguagens Naturais, e as regras de extração são tipicamente baseada em padrões envolvendo o aspecto sintático e semântico. A capacidade do homem de processamento ainda é melhor, mas resultados expressivos vem sendo obtidos no processamento em textos sem estrutura. O entendimento de textos sem restrição em Linguagem Natural ainda está longe de ser resolvido por completo, entretanto, métodos de EI funcionam porque dependem de restrições e padrões que desejamos extrair dos textos \cite{Soderland1999}. 

          \item[II.] \emph{\textbf{Documentos semi-estruturados}} : Não são textos totalmente livres de estrutura, mas também as estrutura existente não é tão rígida, encontram-se no intermédio. Técnicas de PLN concebem regras para a extração de textos livres, contudo, estas regras funcionam perfeitamente para gramáticas livre de contexto onde encontramos sentenças inteiras para analisar, fato que nem sempre ocorre em textos semi-estruturados. Regras muito simples utilizadas em textos puramente estruturados não serão eficientes também.
          
          O pesquisador Sergel Abiteboul diferencia dentro do contexto de semi-estruturados, em cinco categorias \cite{Abiteboul1997}, \cite{Silveira2001}:
          \begin{itemize}
            \item \textbf{Estrutura Irregular} - Quando uma informação está disposta de mais de uma maneira na estruturação do documento,e.g., o campo de endereço, o qual poderiamos encontrar como uma única \emph{string} representando todo o endereço, ou vários campos como \emph{string} para o nome da rua, um campo de inteiro para o número do logradouro, etc.;
            \item \textbf{Estrutura Implícita} - A estrutura existe, mas não é algo natural e possivelmente necessita de algum processamento, e a representação lógica dos dados não é de imediato obtida. Podemos configurar as páginas em \emph{HTML} nesta categoria, que é puramente texto, mesmo contendo \emph{tags}, não deixa de ser um documento semi-estruturado de puro texto, onde é necessário um processamento de suas \emph{tags} para a obtenção de alguma informação preliminar.;
            \item \textbf{Estrutura Parcial} - Identificamos parte da estrutura de dados, mas a outra parte, muitas vezes não é necessária ou não é passível de identificação, necessitando uma extração;
            \item \textbf{Estrutura Indicativa} - Quando encontramos os dados indicados,e.g., o dado de endereço já possui uma estrutura definida, podendo assumir outras formas, mas geram transtorno para a modificação do esquema adotado. Muito utilizado quando ocorre uma padronização dos dados \cite{Abiteboul1997};
            \item \textbf{Estrutura Flexível} - A instância do objeto consegue assumir outras formas de dados, sendo isso nativo da estrutura em si.
          \end{itemize}
          
          Algumas ferramentas pioneiras em pequisas de dados semi-estruturados na \emph{World Wide Web} foram:  \emph{Yahoo\footnote{Yahoo - http://www.yahoo.com}} e \emph{Altavista\footnote{Altavista - http://www.altavista.com}}. Utilizam uma técnica chamada \emph{full text search}, que desconsidera a semântica, comparando o texto completo com as entradas do usuário \cite{Silveira2001}.
            
          Entretanto, como apresenta um mínino de estruturação, alguns padrões podem ser construidos, limitando sua utilização na extração.
          
          \item[III.] \emph{\textbf{Documentos estruturados}} : Informações textuais contidas em banco de dados ou qualquer outro gênero de documento com uma estruturação rigída, são a base de textos estruturados. Como seguem uma moldura sem grandes diferenças de um documento para outro, sua informação é facilmente extraida.

        \end{itemize}

	\subsection{Fluxo Geral}\label{EI:fluxo}

		A estrutução de um sistema de EI basea-se em alguns passos: Tokenização, Processamento Léxico e Morfológico, Análise Sintática e Análise do Domínio. O sistema pode possuir apenas algumas das etapas, e não necessariamente deve cobrir todas as etapas para ser considerado um sistema de EI. As necessidades da aplicação que direcionam as diretrizes dos passos os quais o sistema deve cobrir. Na figura~\ref{fig:EI-estrutura} ilustramos os quatro principais módulos \cite{Appelt1999}.
		
			\begin{figure}[htb]
				\begin{center}				
					\includegraphics[scale=0.5]{./figuras/EI-estrutura.png}				
				\end{center}
				\caption{Principais módulos de um sistema de Extração de Informação}
                \label{fig:EI-estrutura}
			\end{figure}
			
		Para melhor ilustrar o processo de Extração, vamos exemplificar aplicando sobre a sentença ``O dia é belo'' as quatro etapas do processo.
		 
		Tokenização é a etapa onde dividimos os textos em tokens. Em EI, comumente adota-se a definição de um \emph{token} sendo as palavra separadas por espaço, e.g., na frase ``O dia é belo'', obtemos quatro tokens: ``O'', ``dia'', ``$\acute{e}$'' e ``belo''. Este exemplo ilutra o processo de Tokenização. Em alguns idimas este processo é simples, mas em outros idiomas não o é, pela falta de estruturação e uma não distinção clara dos limites de uma palavra, e.g., Japonês, Chinês.
		
		 O Processamento Morfológico e Léxico, adiciona informações através de \emph{tags} classificando léxica ou morfológicamente os \emph{tokens} para posterior utilização, e.g., ``$O_{artigo}$'', ``$dia_{substantivo}$'', ``$\acute{e}_{verbo}$'' e ``$belo_{adjetivo}$''. Neste exemplo, aplicamos regras gramáticais da língua Portuguesa, mas podemos adotar outras regras como: tamanho da palavra, maiúsculas e minuscúlas ou outras criadas a partir do problema a ser resolvido.
		 
		 Muitos sistemas de Extração de Informação são construídos sobre a língua inglesa, que não necessita uma análise morfológica muito aprofundada onde uma lista com as variações das palavras seria o suficiente. O idioma alemão por sua vez, é essencial fazer uma análise morfológica, pois é composto por palavras aglutinadas \cite{Appelt1999}. 
		 
		A maior parte da análise do texto é feita através de um conjunto de expressões regulares \cite{Grishman1997}. A Análise Sintática objetiva estudar a função que as palavras desempenham. Para muitos domínios, o simples processo de obtenção de sujeitos, predicados e argumentos resolvem a maioria das sentenças. Se a expressão encontrada estiver inserida no conjunto de expressões regulares, tão logo ela receberá um marcador, e dependendo do sistema, outros recursos. Com isto dividimos nossa sentença original em ``$O dia_{Sujeito}$'' e ``$\acute{e} belo_{Predicado}$''.
		 
		 Para demonstrar a Análise de Domínio, tomamos como regra, a obtenção dos substantivos dos sujeitos. Com isto, conseguimos extrair ``dia'' de nossa sentença original. E finalizamos o processo de extração.

		O processo de Extração de Informação pode ser abstraído em duas grandes partes. Primeiramente a extração \textbf{fatos} individuais do texto através de uma análise textual. Então, a integração destes fatos, aumentando os fatos já obtidos ou criando fatos novos. E por fim, os fatos pertinentes ao cenário, nós transformamos para o formato de saída \cite{Grishman1997}. Para isto, o processo passa por algumas complexidades que se relacionam diretamente com os módulos que utilizaremos.		
		      
		\paragraph{Fatores de complexidade}	Como a Extração de Informação trabalha com textos, enfrentamos dificuldades como a língua na qual é escrita, o gênero do documento, propriedades e a própria tarefa que efetuaremos sobre o documento \cite{Appelt1999}.
		
			\subparagraph{Idioma} Os documentos se encontram escritos em algum idioma, tão logo nos defrontamos com nossa primeira dificuldade. Algumas línguas necessitam de tratamento morfológico, espaçamento entre palavras e segmentação de palavras. 
			
			\subparagraph{Gênero} O gênero do documento com o qual se vai trabalhar influência também. Se limitarmos nossa ferramenta a textos de anúncios de jornais, não é o mesmo que extrairmos informações de artigos científicos. Como consequência, o uso da linguagem formal ou informal é extremamente ligada ao documento também.
			
			\subparagraph{Propriedades} Os textos podem conter tabelas, imagens, gráficos entre outros tipos de informação não textual que necessitam de formas especiais de tratamento.
			
			\subparagraph{Tarefas} As tarefas efetuadas pelo sistema também entram na nossa análise de complexidade. Uma ferramenta que apenas procura entidades, possui uma abordagem diferente de uma que procura propriedades a mais de um entidade.
			
		Sistemas de Extração de Informação trabalham com o processamento de muitos documentos e um espaço muito curto de tempo. Então, para não prejudicar o desempenho, utiliza-se máquinas de estado finito em abundância. O alvo da extração de uma Extração de Informação pode ser uma relação de \emph{n-tuplas} ou muito mais complexa considerando a hierarquia e organização dos dados. 
		
		Programas que realizam a tarefa de Extração de Informação são usualmente chamados de \emph{extratores} ou \emph{wrappers}. Um \emph{wrapper} geralmente executa a tarefa de encontrar padrões, e estes dependem de um conjunto de regras. Adaptar um sistema de Extração de Informação tem muitos pontos a serem observados: tipo de texto, domínio, cenário, conjunto de regras \cite{Chang2006}.
								
		O Reconhecimento de Nomes em um texto é uma tarefa de destaque, uma vez que nomes aparecem frequentemente em todos os tipos de texto, e de muitas maneiras. Os nomes aparecem em um conjunto de padrão, podendo conter prefixo ou sufixo, estar escrito com letras maíusculas, facilitando assim sua extração. Observando a tabela~\ref{tab:exemplos_nome}, temos algumas maneiras de como o nome João José da Silva Pereira Junior pode aparecer em um texto.

		% Tabela com exemplos de aparição de nomes
		\begin{table}[htbp]
		  \centering   
		    \begin{tabular}{rrrr}
		    \addlinespace
		    \toprule
		    {\bf Exemplos de aparição de nomes} \\
		    \midrule
		    João José da Silva Pereira Junior \\ 
		    João José da Silva Pereira Jr. \\
		    João J. da Silva Pereira Jr. \\
		    João J. S. P. Jr.\\
		    Sr. João Pereira Jr. \\
		    JOÃO JOSÉ DA SILVA PEREIRA JUNIOR \\
		    JUNIOR, João J. S. P.		    
		    \bottomrule
		    \end{tabular}
			\caption{Exemplos de aparição de nomes}
		  \label{tab:exemplos_nome}
		\end{table}

		Alguns sistemas não tem fases distintas para léxica e sintatica, outros implementam um \emph{parser} para a sentença inteira. Em geral, os sistemas utilizam partes que possuem certeza sobre sua construção, tanto sintaticamente quanto semanticamente. Na analise sintática, podemos ainda ter muitas interpretações ambíguas, para tal, a semântica e o domínio especifico da aplicação eliminam outras interpretações do dados extraídos.
		
		Construir uma estrutura completa de análise sintática é extremamente complicada. Algumas decisões são particularmente difíceis e dependem do contexto. \emph{Parsers} que buscam avaliar sentenças inteiras pecam no aspecto das decisões locais, pois procuram ser generalistas para não excluirem algumas opções, acarretando em extrair conteúdos a mais sem muito significado para o domínio. Se as relações sintaticas forem corretamente extraidas, a interpretação dos modelos de cenário serão mais simples e corretas.

\section{Avaliação}\label{EI:avaliacao} 
		
		Os critérios de avaliação consistem em: quanta informação foi extraída(\textit{recall}), quanto da informação extraída é correta(\textit{precision}) e quanto da informação extraída é supérflua(\textit{overgeneration}) \cite{Sundheim1991}. As conferência \textit{MUC} têm um papel fundamental na definição dessas medidas, na necessidade de avaliar os sistemas de Extração de Informação. Inicialmente as medidas de precisão e cobertura foram herdadas do sistema de avaliação de Recuperação de Informação. Como as técnicas de Extração e Recuperação são distintas, os nomes foram mantidos, porém as definições das medidas foram alteradas \cite{Gaizauskas1998}.
		 
		\begin{itemize}
          	\item \textbf{Cobertura ou Abrangência}(\textit{Recall}) : Quanto da informação extraída é relevante. Ou seja, é medida através da informação corretamente extraída($N_{extraido-correto}$) sobre a informação relevante na página($N_{total-extraidos}$). Representada pela fórmula~\ref{formula:cobertura}
          	
          	\begin{equation}\label{formula:cobertura}
              Cobertura = \frac{N_{extraido-correto}}{N_{total-extraidos}}              
            \end{equation}            
    	
          	\item \textbf{Precisão}(\textit{Precision}) : Quanto da informação extraída é correta. É obtida através da informação corretamente extraída($N_{extraido-corretos}$) sobre a informações extraídas ($N_{resposta}$).
          	
          	\begin{equation}\label{formula:precisao}
              Precis\~{a}o = \frac{N_{extraido-correto}}{N_{resposta}}
            \end{equation}
						
			Importante ressaltar que $N_{total-extraido}$ e $N_{resposta}$ são inversamente proporcionais, isto é, quando a \emph{Cobertura} aumenta, a \emph{Precisão} tende a diminuir e vice-cersa. \emph{Precisão} e \emph{Cobertura} estão sempre no intervalo de $[0, 1]$, sendo 0 o pior resultado e 1 o melhor.
			  
  		 	\item \textbf{\textit{F-measure}} : A \textit{F-measure} mede considerando a precisão e a cobertura. O parâmetro $\beta$ controla o balanceamento entre a cobertura e a precisão. 
  		 	
  		 	\begin{equation}\label{formula:F-measure}
              F-measure = \frac{(\beta^2 + 1)*Cobertura*Precisão}{\beta^2 * (Cobertura + Precisão)}
            \end{equation}

			$\beta = Cobertura/Precis\~{a}o$, onde encontramos a F-measure sendo orientada para cobertura quando $\beta > 1$  e orientada para a precisão quando $\beta < 1$. Por este motivo, geralmente utiliza-se $\beta = 1$ , balanceando assim as duas medidas, e aplicando na fórmula~\ref{formula:F-measure} temos:

  		 	\begin{equation}\label{formula:F1}
              F_1 = \frac{2*Cobertura*Precisão}{(Cobertura + Precisão)}
            \end{equation}			   

        \end{itemize} 

		Para ilustrar melhor os cálculos, utilizando-se da ferramenta em desenvolvimento pelo autor criada para o projeto \textit{Salus Cyted}, que será discutida no capitulo~\ref{Capitulo 5}. A ferramenta \emph{NameParser} será aplicada na página \textit{Association Alzheimer\footnote{Association Alzheimer - http://www.alz.org/}}, vista na figura~\ref{fig:siteAssociationAlzheimer} como nossa fonte de dados.

			\begin{figure}[htb]
				\begin{center}				
					\includegraphics[scale=0.35]{./figuras/site_nome_grifado.png}				
				\end{center}
				\caption{Homepage da Association Alzheimer com nomes extraidos.}
                \label{fig:siteAssociationAlzheimer}
			\end{figure}

		A regra criada para a extração de nome tem como base as definições da gramática, sendo considerado um nome uma palavra que começa com uma letra maiúscula seguida de letras minúsculas. Como os nomes estão sendo extraídos de páginas \textit{Web}, e elas não possuem uma regra quanto a sua estética, podemos encontrar muitas palavras que não são necessariamente um nome. E isto realmente acontece, como podemos observar na tabela~\ref{tab:termos_extraidos}. 

			\begin{table}[htbp]
              \centering              
                    \begin{tabular}{rrrr}
                        \addlinespace
                        \toprule
                                Termos extraídos \\
                        \midrule                              
                        		Medical & President & Alzheimer & Scientific \\
                                About & Anual & Report & Plan \\                    
                                Ralph & Nixon & Samuel & Lennart \\
                                Michigan & Chicago & National & Office \\                                                             
                        \bottomrule
                    \end{tabular}
                \caption{Exemplos de alguns termos extraidos}
              \label{tab:termos_extraidos}
            \end{table}
		
		Para esclarecer um pouco mais o conceito de Precisão e Cobertura, utilizando-se da tabela~\ref{tab:termos_extraidos}, temos o total de 16 termos extraídos. Desses 16 termos, apenas 4 são nomes corretos e esperávamos no total 8 nomes, então nossa \textbf{Precisão} é de 50\%. Resultando em uma precisão média. A \textbf{Cobertura} são os nomes extraídos corretamente sobre o total de termos que extraímos, resultando em apenas 25\%. Isso significa que de toda informação extraída, apenas 25\% é relevante para o domínio do sistema. Note que extraimos nomes como Michigan e Chicago, que estão corretos do ponto de vista de serem nomes, mas são nomes de lugares, e o foco é nome de pessoas.
		
		Temos como resultante a tabela ~\ref{tab:resultados_alzheimerassociation}.
				
            \begin{table}[htbp]
              \centering              
                    \begin{tabular}{rr}
                        \addlinespace
                        \toprule
                              & Página \\
                        \midrule                              
                                Nomes presentes & 8 \\
                                Nomes identificados pelo programa (usando expressões) & 16 \\
                                Nomes corretamente identificados (usando expressões) &  4\\
                                Precisão/Precision & 50\% \\
                                Cobertura/Recall & 25\% \\                              
                        \bottomrule
                    \end{tabular}
                \caption{Resultados da extração}
              \label{tab:resultados_alzheimerassociation}
            \end{table}

        O processo de avaliação é muitas vezes efetuada manualmente ou semi-automatizada. Em algum ponto do processo de avaliação é necessária a intervenção do usuário. Para o sistema saber se um dado termo extraido é um nome, o usuário que possui esse conhecimento passa de alguma maneira para o sistema.
                        
        Devemos lembrar também que o domínio atribuido ao resultado é muito importante, por exemplo, se encontrarmos um nome pela metade, devemos considerá-lo errado ou correto? Quando o nome se repete ao longo do página, devemos conta-lo apenas uma vez ou mais vezes? Questões assim dificultam o critério e devem ser relevadas para uma melhor interpretação dos dados.
        
				
		%Extração de Informação baseada em conhecimento 
		
		%O papel de padrões lingüísticos é sustentar a interpretação de textos na Extração de Informação baseada em conhecimento. Em função da construção de padrões lingüísticos ser um gargalo mesmo em domínios limitados, propôs-se o uso de um mecanismo de aprendizagem indutivo para construir automaticamente uma base de conhecimento de padrões. O sistema automático é construído sempre que se identifica um padrão lingüístico desconhecido. Um pressuposto importante embasando esta pesquisa é o reduzido número de expressões normalmente utilizado para descrever uma informação dentro de um domínio limitado (Kim & Moldovan, 1995).
 
		%Template Mining
		
		%Template Mining ou mineração por modelos é uma técnica de processamento de LN que extrai dados de textos que possuem padrões que permitam o reconhecimento do que se deseja extrair ou de seus arredores. Um modelo contém informação sobre o que procurar no texto e é disparado a extrair determinadas partes devidamente indicadas. Lawson et al., (1996) descreve aplicações de template mining em domínios restritos alegando que esta técnica é própria para áreas cujos textos são claros com frases objetivas e de natureza declarativa.
 
		%Text windowing
		
		%A técnica text windowing é do tipo orientada para corpus de textos que avalia palavras na busca de blocos de palavras que estejam relacionadas por sintática ou propriedades léxicas. Jacquemin (1996), descreve uma aplicação de text windowing em um método para selecionar trechos de textos motivados por propriedades léxicas, combinando informação conceitual em listas de termos com metaregras em filtros semânticos locais.
 
		%Documentos Auto-Explicativos
		
		%Consideramos adequado associar a técnica de template mining com a metodologia proposta por Branting & Lester (1996) para documentos auto-explicativos. Nesta metodologia, os textos são analisados e classificados por sua estrutura retórica. A ligação entre as técnicas se dá pelo aproveitamento das estruturas retóricas como fonte para a definição dos parâmetros dos modelos usados pela técnica de template mining para extração de dados.
 
		%Aquisição de Conhecimento de Textos
		
		%O trabalho publicado pelo Grupo de Engenharia de Conhecimentos de Textos da Universidade de Freiburg através de diversos artigos descreve os esforços para analisar textos que apresentam novas formas de conhecimento. O grupo se utiliza de um parser de LN e almeja a expansão desta base de conhecimento. Da mesma forma que os grupos que tomaram parte dos MUCs, eles também usam técnicas com modelos; entretanto, eles permitem que novos modelos sejam adicionados como resultado da aprendizagem de conceitos (Hahn, & Schnattinger, 1997).

		%O ponto central da pesquisa do grupo trata-se da aquisição de conhecimento de textos que ocorre com a aprendizagem de conceitos que alimenta um sistema de compreensão de linguagem natural. A aprendizagem de conceitos em uma plataforma de compreensão de linguagem natural é orientada para os recursos através do uso de um Machine Readable Dictionary MRD e é orientada por contexto. Os autores alegam que inferir o significado das palavras baseando-se em informações sobre o contexto é mais confiável do que procurar por seu significado em um MRD. A aprendizagem de conceitos é concebida com o desenvolvimento de uma abordagem de aprendizagem de raízes simbólicas. Um exemplo de aquisição de conceito é descrito em Hahn et al. (1996). O projeto do grupo visa duas aplicações práticas de aquisição de conhecimento de textos da língua alemã: artigos sobre testes de produtos de tecnologia de informação (100 documentos com 10^5 palavras) e artigos sobre descobertas médicas (120,000 documentos com $$10^7 palavras).

		%O trabalho descrito por Mauldin (1991) usa a compreensão parcial de textos obtida através de um parser que realiza text skimming para recuperação de informação conceitual, utilizando um banco de dados de scripts que, por sua vez, é alimentado por um método de aprendizagem e um MRD que aprimora o conhecimento léxico. A recuperação de informação executada pelo sistema ferret é referida como recuperação de informação conceitual porque ao invés de realizar a busca através do uso de palavras-chave (baseada em palavras) é usado conhecimento sobre os conceitos.

		%Um ponto de vista interessante sobre o problema de aquisição de conhecimento de textos é descrito em Futrelle & Zhang (1994) que apresenta técnicas de bootstrap que podem descobrir a estrutura de ordem da linguagem natural e definir classes de palavras presentes em corpus de textos. A definição de classes de palavras é baseada no princípio da substituição onde o significado de uma palavra é encontrado pela comparação dos contextos onde as palavras aparecem e onde elas podem ser substituídas por outra palavra da mesma classe. 