%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Trabalho de Conclusão de Curso
% Aluno: Mario Henrique A. C. Adaniya
% Orientador: Prof. Dr. Mario Lemos Proença Jr.
% Curso: Ciência da Computação - Universidade Estadual de Londrina
% 
%  Capitulo sobre Mineração de Dados na WEB
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Mineração de Dados na WEB} \label{WebMining}

		No inicio, a \textit{Web} continha páginas estáticas objetivando um acesso cômodo as informações. Muitas páginas eram manualmente implementadas, sem contemplar muito a interação com o usuário. Geralmente seguiam a direção servidor-usuário.
		
		Com a expansão e o acesso crescente, as páginas começaram a evoluir, assim como a \textit{Web}. Tornando-se dinâmica, onde encontramos páginas construídas interagindo-se com o usuário. Nos encontramos neste estágio evolutivo, e caminhamos para um futuro muito mais brilhante.
		
		E como a evolução não tem fim, estamos observando a concepção da \textit{Web} Semântica, discutida na seção~\ref{webminig:semantica}. Onde apenas apresentar as informações para o usuário não é o suficiente, como é preciso, expressar de uma forma semântica também para o entendimento das máquinas.
		 
		Alguns problemas podem ser encontrados pelos usuários quando interagem com a \textit{Web} \cite{Kosala2000}:
  
		 \begin{itemize} 
		   \item[a.] \textbf{Achar informações relevantes} - Os usuários quando utilizam serviços de pesquisa, procuram através de palavras-chaves alguma informação na \textit{Web}. O resultado da busca, as vezes, é enorme e com isso temos: resultados relevantes, pouco relevantes ou sem relevância;
		   
		   \item[b.] \textbf{Personalização da informação} - Usuários diferentes, interagem diferentemente e querem conteúdos diferentes, logo, temos o problema no lado do usuário e do próprio provedor;   
		 \end{itemize}
    
		A \textit{Web Mining} foi concebida devido aos estudos nas mais diversas linhas de pesquisa: extração de informação, inteligência artificial, banco de dados, recuperação de informação e entre outras áreas. Ela faz parte de um todo, que auxiliam de uma maneira para a resolução dos problemas acimas citados.

\section{Web Mining}
	
		\textit{Web Mining} é o uso das técnicas de Mineração de Dados para descobrir e extrair automaticamente a informação de documentos na \emph{Web} \cite{Etzione1996}. A Mineração de Dados refere-se ao processo não trivial de identificação de padrões válidos, previamente desconhecidos e potencialmente úteis de dados \cite{Frawley1992}. Seguindo o conceito de Etzione, que utiliza da Descoberta do Conhecimento (\textit{KDD - Knowledge Discovery Database}) como base, ele decompõe a Web Mining em quatro tarefas: \emph{Resource finding} (Coleta de Documentos), \emph{Information selection and pre-processing} (Pré-processamento), \emph{Generalization} (Extração de Padrões) e \emph{Analysis} (Análise).        		
		
		É importante ressaltar que \emph{Web Mining} é diferente de Recuperação da Informação e Extração da Informação. Mas uma combinação das técnicas em si são utilizadas nas etapas do \emph{Web Mining}.
		
\section{Descoberta do Conhecimento}

		Muitas são as definições que os pesquisadores adotam para KDD ou Mineração de Dados, a mais difundida e adotada é encontrada nos trabalhos de Fayyad e seu grupo de pesquisa \cite{Fayyad1996a}: 

		\begin{flushright}
		     \parbox{4.0in}{\footnotesize{\emph{Knowledge Discovery Database} é o processo não trivial de identificação de padrões válidos, novos, potencialmente úteis e compreensiveis que estejam presentes nos dados.}}
		\end{flushright}
 
%		\begin{quote}
%        	\emph{Knowledge Discovery Database} é o processo não trivial de identificação de padrões válidos, novos, potencialmente úteis e compreensiveis que estejam presentes nos dados.
%        \end{quote}

	 	Tomamos como definição que: os \emph{dados} são um conjunto de fatos, e \emph{padrões} são definidos em uma linguagem e descrevem um subconjunto dos dados ou um modelo aplicável aquele conjunto.
	 	
	 	O processo de \emph{Knowledge Discovery Database} é um processo interativo e iterativo, composto por algumas etapas, resultando na extração de padrões. As etapas sofreram mudanças no decorrer de seus estudos, alcançando nove etapas \cite{Fayyad1996b}, sendo reduzida para quatro \cite{Weiss1998} e maturando-se num ciclo \cite{Rezende2003}. Atualmente, este ciclo se divide em: Identificação do problema, Pré-Processamento, Extração de Padrões, Pós-Processamento e Utilização do Conhecimento \cite{Alvarez2007}. A figura~\ref{fig:WM-KDD} ilustra a última abordagem utilizada.
	 	
	 	\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.5]{./figuras/processo-kdd.png}				
			\end{center}
			\caption{Etapas do processo KDD \cite{Rezende2003}}
            \label{fig:WM-KDD}
		\end{figure}
	 	 
	 	 \subsection{Identificação do Problema} %\paragraph{Identificação do Problema}
	 	 
	 	 Para iniciarmos todo o processo, precisamos ter um conhecimento mínimo que seja do domínio com o qual iremos trabalhar, e devemos ter claro o objetivo que almejamos. Nesta fase, construímos nosso conhecimento e todas as etapas posteriores são dependentes de uma análise que cubra as metas, objetivos e restrições. Criamos o conceito de útil para o sistema e para o usúario nesta fase.
	 	 
	 	 \subsection{Pré-Processamento} %\paragraph{Pré-Processamento}
	 	 
	 	 Muitas vezes os dados não se encontram formatados adequadamente para a utilização na etapa de extração de padrões, ou outras características limitam a aplicação. Para adequá-los alguma tarefas podem ser inseridas no Pré-Processamento: Integração, Transformação, Limpeza e Redução de Dados.
	 	 
	 	 	\begin{itemize}
                \item \textbf{Integração:} Os dados muitas vezes são provenientes de diversas fontes, precisando uma unificação. Obtemos nesta fase, uma fonte única de dados para utilizar nas etapas posteriores \cite{Alvarez2007}.
                \item \textbf{Transformação:} Para minimizar as diferenças encontradas nos dados para melhorar sua extração, algumas transformações aplicadas são: normalização, transformação de tipo, discretização de atributos quantitativos, entre outros \cite{Batista2003}.
                \item \textbf{Limpeza:} Com o conhecimento adquirido no passo de Identificação do problema, temos um embasamento melhor para remover dados indesejáveis. Alguns atributos podem estar preenchidos incorretamente \cite{Alvarez2007}.
                \item \textbf{Redução:} Muitas vezes somos obrigados a limitar nossa ação diretamente ligados a inúmeros fatores. O volume pode ultrapassar a capacidade de processamento, sendo isto observado quando executamos muitas vezes os experimentos \cite{Weiss1998}.
              \end{itemize}
	 	 
	 	 \subsection{Extração de Padrões}%\paragraph{Extração de Padrões}
	 	 	
	 	 Os objetivos definidos na Identificação do Problema direcionam este passo. A execução deste passo pode ser necessária muitas vezes para procurar o resultado mais perto do objetivo. As tarefas de Mineração de Dados como classificação, \emph{clustering} e regras de associação são empregadas nesta etapa de acordo com o modelo escolhido para ser gerado \cite{Alvarez2007}.
	 	 
	 	 \subsection{Pós-Processamento} %\paragraph{Pós-Processamento}
	 	 
	 	 Depois de extraídos os padrões, o ciclo do processo ainda não é fechado, pois se apresentarmos todos os padrões ao usuário como extraimos, podemos mostrar padrões muito complicados ou que fujam dos objetivos. Com a qualidade questionável podemos executar novamente algumas etapas ou o processo inteiro. Para mensurar a qualidade temos alguns artificios como interessabilidade, compreensibilidade, precisão, cobertura e taxa de erro \cite{Alvarez2007}.
	 	 
	 	 \subsection{Utilização do Conhecimento} %\paragraph{Utilização do Conhecimento}
	 	 
	 	 Última fase do processo é onde expomos o conhecimento extraído para o usuário, ou ocorre a integração a um sistema.
	 	 
	 	 A utilização dos termos Mineração de Dados ou \emph{Knowledge Discovery Database} na literatura é muito nebulosa. Alguns autores consideram como sendo processos distintos, outros processos que se complementam ou nomeia o mesmo processo. Adoto neste trabalho como sendo tarefas complementares.

\section{Etapas do Web Mining}

		Basicamente utilizamos os mesmos conceitos de \emph{Knowledge Discovery Database} alterando a fonte de dados. Como nossa única fonte, utilizamos a \emph{World Wide Web}. No inicio das pesquisas muitos acreditavam, e ainda acreditam, que a \emph{Web} é muito instável como fonte de dados, devido a suas proporções e falta de estruturação. Muitas informações são encontradas em Linguagem Natural pois o público-alvo são os humanos. Alguns defenderam a posição de transformar a \emph{Web} em um banco de dados, mas foram vencidos pelo temperamento caótico e dinâmico \cite{Etzione1996}.
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.5]{./figuras/processo_webmining.png}				
			\end{center}
			\caption{Etapas do processo de Web Mining}
            \label{fig:WM-processo_WebMining}
		\end{figure}

	\subsection{Coleta de Documentos}
	
		A Coleta de Documentos é uma etapa essencial para todo o processo. Definimos com quais documentos o trabalho sera efetuado. Em algumas situações os documentos fazem parte do problema como um todo, logo estarão disponiveis de inicio. Porém, em outras situações, é necessário o processo de Coleta de Documentos \cite{Alvarez2007}.
		
		Na grande rede mundial interligando computadores, desde seu inicio, houve uma comoção para facilitar a busca de documentos. Dois grandes grupos são observados na construção de indexadores: Motor de Busca e Diretório WWW \cite{Baeza-Yates1998}.
		
		\begin{itemize}
          \item \textbf{Motor de Busca(\emph{Search Engine}):} Este grupo são formados por motores de busca que utilizam abordagens baseados em rôbos, mega-indexadores, entre outras abordagens automatizadas. O índice criado é centralizado para responder consultas do mundo inteiro. Em 1998, os indexadores que cobriam a maior área eram: \emph{HotBot\footnote{HotBot - http://www.hotbot.com}}, \emph{AltaVista\footnote{AltaVista - http://www.altavista.com}}, \emph{Nothern Light\footnote{Nothern Light - http://www.nothernlight.com}} \cite{Lawrence1998}. Atualmente, o ranking é composto por: \emph{Google\footnote{Google - http://www.google.com}}, \emph{AlltheWeb\footnote{AlltheWeb - http://www.alltheweb.com}}, \emph{AltaVista} \cite{Vaughan2004}. Alguns \emph{search engines} se especializam em tópicos, como o \emph{SearchBroker\footnote{SearchBroker - http://www.searchbroker.com}}. Neste grupo, incluimos também os \emph{metaseachers}, que são serviços disponiveis que coletam respostas de diversos \emph{search engines} e unificam. Como exemplos, temos o \emph{MetaCrawler\footnote{MetaCrawler - http://metacrawler.com}} e \emph{SavvySearch\footnote{SavvySearch - http://www.savvysearch.com}} \cite{Baeza-Yates1998}.
 
          \item \textbf{Diretório WWW:} Utiliza uma classificação próxima do conhecimento humano, na representação de diretórios de assunto, que se estruturam como árvores. Uma grande vantagem desta técnica é a resposta ser, na maiora dos casos, útil. A desvantagem é a falta de especialização e volume de páginas classificadas, esta última desvantagem se deve ao crescimento exponencial de informações que são inseridas na \emph{WWW} todos os dias. Um grande exemplo deste grupo é o \emph{Yahoo!\footnote{Yahoo! - http://www.yahoo.com}} \cite{Baeza-Yates1998}.
          
        \end{itemize} 
        
        Um ponto muito importante nesta etapa, é que os documentos coletados estarão na sua maioria em muitos formatos, sendo necessário um tratamento para unificar um padrão.
	
	\subsection{Pré-Processamento}
	
		Após a coleta de todos os documentos possiveis, na etapa anterior, partimos para o pré-processamento destes documentos. É nesta etapa que transformamos uma coleção de documentos em uma representação estruturada adequada. O custo computacional é elevado. Constantemente é adotado a representação de um documento como um conjunto de palavras, chamado de abordagem \emph{bag-of-words} \cite{Alvarez2007}.
		
		\paragraph{Representação de Documentos} A abordagem \emph{bag-of-words} consiste em representar cada documento da coleção como um vetor de termos contidos no mesmo. Cada termo que ocorre no documento pode ser composto por apenas uma palavra ou várias palavras. Para identificar todos os termos presentes, é efetuado uma \emph{tokenização} dos termos \cite{Alvarez2007}. 
		
		\paragraph{Redução de Representação} Feita a representação, podemos ter em mãos um volume enorme para processar, e as vezes, somos limitados no processamento e armazenamento de tanta informação. Com esta finalidade, utilizamos algumas técnicas para auxiliar na redução:
		
			\subparagraph{Filtragem} Na filtragem, almejamos a remoção de termos com pouca ou nenhuma relevância para a análise. Em geral, removemos artigos, preposições e conjunções.
			
			Podemos também supor que termos que aparecem muitas vezes no documento, não revelam muitas informações sobre o documeto. Analogamente, termos que aparecem pouco também podem ser excluidos \cite{Yang1997}.
			
			\subparagraph{\textit{Stemming}} Nos documentos, as palavras podem ser encontradas flexionadas em diversas formas e as vezes compartilham a mesma raiz semântica. O processo de \emph{steamming} consiste em reduzir estas formas encontradas na raiz (\emph{stem}). Podemos citas Porter \cite{Porter1997} e Lovins \cite{Lovins1968} como grandes pesquisadores nesta área. Para a lingua portuguesa, temos o \textit{STEMBR : A stemming algorithm for the brazilian portuguese language}.

		Filtragem e \emph{Stemming} são apenas algumas das técnicas envolvidas no Pré-Processamento, podemos adotar muitas outras que trabalham no âmbito semântico, hierarquico, com atributos relevantes, etc.
		
		\paragraph{Pré-processamento Linguístico} Esta etapa é essencial em cenários onde a mineração tem como objetivo o reconhecimento de nomes próprios, lugares e organizações, e se faz necessário um pré-processamento linguístico. As seguintes tarefas são adotadas no processo:
		
		\begin{itemize}
		  \item \textbf{Etiquetagem morfossintática (\emph{Part-Of-Speech Tagging})} No texto, encontramos palavras, símbolos, fórmulas matematicas, entre outros termos. A etiquetagem morfossintática tem como tarefa atribuir uma etiqueta para cada termo encontrado de acordo com sua categoria. 
		  
		  \item \textbf{Reconhecimento de frases} Com o agrupamento de termos, analisando o documento, tem como objetivo formar sentenças \cite{Weiss1998}.
		  
		  \item \textbf{Desambiguação no sentido de palavras} A ambiguidade pode gerar transtornos em análises futuras, por isto, procura-se eliminar qualquer ambiguidade no sentido das palavras. Em algumas linguas essa eliminação é facilmente alcançada, porém, outras precisam de um conhecimento muito mais aprofundado na própria lingua e o dominio da aplicação.
		  
		  \item \textbf{\emph{Parsing}} Com a geração da árvore sintática de uma sentença, criamos a possibilidade de analisarmos a relação existente entre as palavras da sentença. Podemos extrair o sujeito, objeto, entre outros, analisando a função exercida pela palavra no contexto da senteça \cite{Alvarez2007}. 
		   
        \end{itemize}
        
        As técnicas são frequentemente utilizadas visando uma melhoria para a utilização na Mineração de Dados.
						
	\subsection{Extração de Padrões}
	
		Após o tratamento dos documentos e seus dados, temos como resultado um conjunto em formatos que terão um aproveitamento melhor para a Extração de Padrões. Com a aplicação da Extração de Padrões a obtenção de um conhecimento útil e interessante para o usuário será possivel.
		
		Algumas tarefas relacionadas com a Mineração de Dados, utilizam muitos algoritmos de Aprendizado de Maquiná, que também são utilizados na Extração de Padrões.
		
		\paragraph{\emph{Clustering} de Documentos} Com a coleção de documentos em mão, o processo de agrupar os documentos similares, agrupando assim documentos com conteúdos relativamente similares. Estes grupos recebem o nome de \emph{cluster}, e o processo de \emph{Clustering} de Documentos. No final deste processo, teremos cluster com documentos similares, mas clusters distintos entre si \cite{Zhong2003}.
		
		\paragraph{Categorização} A partir de um conjunto de classificação pré-definido, com um documento novo induzimos um classificador a enquadra-lo numa categoria. Muitas dificuldades são encontradas, pois o documento pode pertencer a nenhum, uma ou mais categorias \cite{Yang1997}.
		
		\paragraph{Extração de Informação} Como Wilks define, Extração de Informação, extrai informação de textos em documentos, utilizando computadores numa velocidade alta, e normalmente encontrada de fontes eletrônicas. Prece de uma fase de Recuperação de Informação, que seleciona um conjunto apropriado para a extração \cite{Wilks1997}. Extração de Informação é discutido no capítulo~\ref{EI}.
		
		\paragraph{Sumarização} O processo de Sumarização consiste em construir um terceiro documento contendo um sumário com as informações mais importantes do documento análisado, buscando sempre que este sumário contenha metade ou menos do tamanho do documento original. Identificar partes importantes no documento continuam sendo um grande desafio nesta área \cite{Radev2002}.
		
		Extração de Informação e Mineração de Dados partilham algumas dificuldades como a estruturação do documento, a língua e o estilo de linguagem utilizada na formatação do documento, e o próprio conteúdo do documento.  
			
	\subsection{Avaliação e Interpretação de Resultados}
	
		Para concluirmos o ciclo ou refazer algumas etapas, avaliamos o quanto o processo se aproximou do objetivo almejado. A avaliação pode ser feita pelos usuários finais ou especialistas, que possuem um conhecimento profundo do dominio \cite{Alvarez2007}.
		
		Algumas das métricas são compartilhadas com a Extração de Informação, como Precisão, Cobertura ou \emph{F-measure}. Elas são abordadas no capitulo~\ref{EI} na seção~\ref{EI:avaliacao}.
		
		A ilustração dos dados em elementos gráficos pode, e muito, auxiliar a análise e compreensão dos dados por seres-humanos. Conseguimos interpretar, armazenar muito mais informações gráficas do que tabelas, diferentemente das máquinas. Podemos trabalhar com dados muito mais complexos através de gráficos, podendo assim interagir com decisões muito mais rápidas. O tipo de gráfico empregado para a visualização é de extrema importância, uma vez que se escolhermos gráficos que sejam difíceis de interpretar, em nada ajudarão na avaliação \cite{Keim2002}.

\section{Categorias de WEB Mining}
		
		Com o crescimento exponencial das fontes de informação disponiveis na \emph{World Wide Web} ao nosso redor, cresce a necessidade de automatizar ferramentas que busquem as informações desejadas e corretamente. Ferramentas mais eficazes no rastreamento, tanto do lado dos servidores como dos clientes, são comumente alvos de pesquisas e projetos na busca de uma mineração de dados. Do lado dos servidores, temos extensas listas de \emph{logs}, registros de usuários ou perfil de usuário, entre outros itens que podem ser análisados \cite{Cooley1997}. Na figura~\ref{fig:WM-toxonomia} podemos observar um esboço da taxonomia.  
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.6]{./figuras/WB-taxonomia.png}				
			\end{center}
			\caption{Taxonomia da Mineração na WEB}
            \label{fig:WM-toxonomia}
		\end{figure}

		Esta taxonomia pode ser montada através da junção dos trabalhos de Cooley \cite{Cooley1997} e Kolari \cite{Kolari2004}.
	
		\subsection{Mineração de Conteúdo}\label{webmining:conteudo} 
		
		A falta de estruturação que domina as fontes de informação na \emph{Internet} dificulta a organização, administração, manutenção e busca automatizada de informação. As \emph{search engines} são ferramentas que provêm algum conforto, mas geralmente não filtram, interpretam os documentos que retornam nas buscas \cite{Cooley1997}.
		 
		 A Mineração de Conteúdo e a Recuperação de Informação são muitas vezes utilizadas em conjunto. Enquanto uma realiza a mineração diretamente do conteúdo dos documentos a outra incrementa o poder de busca de outras ferramentas e serviços. Áudio, vídeo, dados simbólicos, metadados e vínculos de hipertexto fazem parte do conteúdo de documentos da \textit{Web} atualmente, e como tal, na mineração de conteúdos também são analisados. Existem áreas de pesquisas destinadas a mineração de dados multimídias, entretanto, como uma enorme parte da \textit{Web} é constituída de texto e hipertexto, permanecendo assim o foco em dados de texto.
		
		Com o continuo crescimento da \emph{Web}, as pesquisas voltadas para ferramentas mais eficazes, melhorias nas técnicas de mineração e extração de dados se desenvolveram. Podemos observar duas grandes abordagens quando tratamos de Mineração de Conteúdo: Baseado em Agente (\emph{Agent-Based}) e Banco de Dados (\emph{Database}).
		 
		\paragraph{Baseado em Agente (\emph{Agent-Based})} Esta abordagem de mineração de dados trabalha diretamente com o campo de Inteligência Artificial, provendo um sistema autônomo ou semi-autônomo, que trabalha para a coleta de conhecimento e organização das informações na \emph{WEB} delimitado pelo escopo do sistema. Dentro desta abordagem, temos as seguintes categorias: 		
		
			\subparagraph{Agentes de Busca Inteligentes (\emph{Intelligent Search Agents})} Muitos sistemas de Agentes Inteligentes utilizam informações caracteristicas de um domínio para organizar e interpretar essas informações de uma forma totalmente autônoma. Como exemplo, temos alguns trabalhos como o \emph{Harvest} \cite{Bowman1995}, \emph{FAQ-Finder} \cite{Hammond1994}, \emph{OCCAM} \cite{Kwok1996} e \emph{ParaSite} \cite{Spertus1997} que extraem e interpretam documentos através de um dominio específico. Outros agente como \emph{ShopBot} \cite{Etzione1997} e \emph{ILA (Internet Learning Agent)} \cite{Etzione1995} através de estruturas de fontes de informação não familiares tentam através da interação, aprender novos comportamentos. \emph{ShopBot} coleta informações de produtos em vários sites de venda utilizando apenas informações gerais dos produtos, enquanto o \emph{ILA} aprende com os modelos e traduz para um conceito interno do sistema \cite{Cooley1997}.
								
			\subparagraph{Categorização e Filtragem de Informação} Muitos agentes \emph{Web} utilizam tecnicas de Recuperação de Informação para automaticamente filtrar e categorizar documentos da Web. O \emph{BO (Bookmark Organizer)} combina técnicas de \emph{clustering} e interação com o usuário para orgazinar o conjunto de documentos baseado em informação conceitual \cite{Maarek1996}. O HyPursuit usa informação semântica embutida nos links e no conteúdo em si dos documentos para criar uma hierarquia de \emph{cluster} de hipertextosm e estruturar as informações \cite{Weiss1996}. \emph{Google News\footnote{GoogleNews - http://news.google.com}} atualmente é uma das ferramentas mais populares que classifica noticias de mais de 4.000 fontes \cite{Kolari2004}.
			
			\subparagraph{Personalização} Outra categoria de agentes Web incluem aqueles que obtêm ou aprendem as preferencias do usuário e procuram fontes de informação na \emph{Web} que correspondam aquelas preferências, e possivelmente, utilizando filtragem colaborativa, procuram interesses similares. Exemplos que utilizam esta abordagem são \emph{WebWatcher} \cite{Freitag1995}, \emph{PAINT} \cite{Wiggins1994}, \emph{Firefly} \cite{Shardanand1995} e \emph{Syskill\&Webert} \cite{Pasani1996}.
						 
		\paragraph{Banco de Dados (\emph{Database})} A abordagem de Banco de Dados, como o nome pressupõem, trabalha com a organização e integração dos documentos semi-estruturados para um documento estruturado, como em um banco de dados relacional, usando inclusive consultas e mecanismos de banco de dados para acesso e analise das informações.
		
			\subparagraph{Banco de Dados em Multiníveis} Uma organização das informações em multiníveis é proposto por muitos pesquisadores. No nível principal são encontrados informações armazenadas de forma semi-estruturadas em vários repositórios na \emph{Web}. Em níveis acima do principal, encontramos meta-dados ou generalizações que são extraídas das camadas abaixo e organizadas de forma com uma estrutura rigida como um modelo relacional ou orientado objeto \cite{Cooley1997}. Em uma das pesquisas desenvolvidas por Han e seu grupo de pesquisa, utilizam um banco de dados de multi-camadas onde cada camada é obtida com operações de transformações e generalização das camadas inferiores \cite{Han1995}. O sistema ARANEUS extrai informações relevantes de documentos de hipertexto e integra em documentos derivados de hipertexto que são generalizações de \emph{views} de banco de dados \cite{Merialdo1997}.
			
			\subparagraph{Sistemas de Consulta Web (\emph{Web Query Systems})} Nesta abordagem, a utilização de \emph{queries} são utilizadas procurando uma aproximação das linguagens de consulta como SQL. Cria-se uma abstração para o usuário final que consulta como se estivesse consultado um banco de dados, quando na realidade existe uma estruturação semântica em cima da semi-estruturada \emph{Web}. Como exemplo, podemos citar \emph{WebLog} \cite{Lakshmanan1996} que utiliza uma linguagem de consulta baseado em lógica para reconstruir a informação extraida das fontes na \emph{Web}. Seguindo a mesma vertente, temos o \emph{WebSQL} \cite{Milo1996}.				
	 
		A área de mineração de textos está bem esclarecida, com muitas técnicas, uma das quais seria reestruturar o documento para uma linguagem entendida pela maquina. Uma mineração que vem ganhando destaque em pesquisas é a mineração em serviços da Web tais como grupo de noticias, grupos de e-mails, lista de discussão. Outro conceito é introduzido por estes pesquisadores, chamado de \textit{Web Intelligence}, que promete transformar os serviços da \textit{Web} em entidades inteligentes, de forma que elas possam interagir e se comunicar através de uma linguagem comum. 

		\subsection{Mineração de Estrutura}\label{webmining:estrutura} 
		
		Como o próprio nome descreve, nesta categoria de mineração estamos preocupados com a estrutura dos documentos \textit{Web} e como estes estão ligados entre si. Os vínculos de ligação de hipertexto são os principais objetos de estudos nesta categoria. Podemos visualizar a \textit{Web} como um grafo orientado, onde os nós representam páginas e as setas entre os pares de nós representam os vínculos entre as paginas. Como ocorre em citações bibliográficas quando um artigo é bastante citado indicando que provavelmente este artigo tem um peso importante perante outros que abordam o mesmo tema, o mesmo pode ser observado entre os documentos \textit{Web}. Podemos drasticamente comparar que se uma pagina contém muitas setas entrando, ela teria certa relevância quanto ao seu conteúdo ser confiável.
		
		Hyperlink-induced topic search (HITS) é um algoritmo para mapear a \emph{Web} e identifica os \emph{hubs} e \emph{authorities}. \emph{Authorities} são páginas bem rankeadas sobre um determinado tópico, e \emph{hubs} são páginas com links para os \emph{authorities}. Como exemplo fundamental, temos que citar o \emph{PageRank} \cite{Page1999} largamente difundido graças ao \emph{Google}. 

 		 \subsection{Mineração de Uso}\label{webmining:uso}
 		 
 		 A mineração de uso utiliza os dados secundários provindos de logs de servidores, logs de browsers, perfis de usuário, cookies, seções ou transações de usuários, pasta favoritos, consultas do usuário, cliques de mouse e qualquer outro dado gerado pela interação do usuário com a \textit{Web}. As aplicações da mineração de dados de uso são classificadas em duas categorias: aprendizado de perfil de usuário (modelagem em interfaces adaptativas) e aprendizado de padrões de navegação de usuário. Talvez umas das técnicas em mais utilização atualmente, devido ao grande número de \emph{E-Commerce}, pois com isto podemos adaptar sites de acordo com o cliente, recomendar produtos de acordo com compras passadas ou baseadas nas similaridades entre perfis de usuários.
 		 
		As organizações estão confiando e conduzindo muitos negócios através da \emph{Internet} e como tal, é necessário técnicas diferentes das tradicionais, pois estas precisam ser revistas. O volume de dados operados diariamente é enorme, tanto dentro quanto fora da empresa. Muito destes dados são gerados automaticamente, e analisar tudo manualmente é um trabalho muito dispendioso, e ao mesmo tempo crucial, pois dados muito importantes estão contidos e podem ser essenciais para uma tomada de decisão para a empresa quanto a estratégia de mercado. Analisando estes dados, as oganizações conseguem estipular vida útil e valor de um determinado produto ao consumidor, estratégias de marketing, campanhas promocionais, entre outros. Dentro das organizações também auxiliam na produtividade, melhorando a comunicação entre os diversos setores através da analise dos dados de intranet \cite{Cooley1997}.
		
		As ferramentas para análise da \emph{Web} praticamente nasceram com elas, tendo mecanismos para medir as atividades do servidor desde os famigerados contadores de visitação. Atualmente, estas ferramentas acoplaram muito mais tarefas como determinar o tempo e o intervalo de visitas além de determinar o número de acessos. Pode-se descobrir quais são os arquivos mais acessados, podendo assim mapear um fluxo de navegação dentro de um determinado domínio \cite{Cooley1997}.
		
 		\paragraph{Ferramentas de Descobrimento de Padrões (\emph{Pattern Discovery Tools})} Com uma combinação sofisticada de muitas áreas como Inteligência Artificial, Mineração de Dados, Psicologia, Teoria da Informação, Economia, Estatística para a mineração do conhecimento e interpretação em um conjunto de dados. Como exemplo, temos a ferramenta \emph{WEBMINER} \cite{Mobasher1997} \cite{Mobasher1996} que descobre automaticamente regras e sequência de padrões através de \emph{logs} de acesso do servidor.

		\paragraph{Ferramentas de Análise de Padrões (\emph{Pattern Analysis Tools})} Uma vez descobertos os padrões, é necessário uma análise sobre os dados extraidos para um aproveitamento do conhecimento obtido. Muitas dessas ferramentas utilizam técnicas onde analistas podem visualizar, interpretar e entender estes dados. A ferramenta \emph{WEBMINER} possui um mecanismo de consulta no estilo da linguagem \emph{SQL}, pois além de extrair o padrão, acopla em suas funcionalidades algumas possibilidades de visualização dos dados extraídos. Mas outras ferramentas como o \emph{WebViz} \cite{Pitkow1994} tem um dos pontos fundamentais para a interação com o usuário apresentando os resultados gráficamente.
		
		A personalização é um dos pontos chaves na Mineração de Uso. Como exemplo, podemos visualizar grandes sites de E-Commerce que sempre buscam personalizar seu site de acordo com as preferências de cada cliente, e.g., se eu sempre procuro livros de informática, o site sempre procura me mostrar ofertas em livros de informática e afins. \emph{Web sites} que demonstram um comportamento de mudar a organização de seu conteúdo e apresentação de acordo com as preferências do usuário são chamados sites adaptativos \cite{Kolari2004}.

        \subsection{Web Semântica}\label{webminig:semantica}
		 
		 A Web Semântica é uma extensão da web já existente, onde a informação ganha melhores
significados, proporcionando aos humanos trabalhar melhor em conjunto com os computadores \cite{Berners-Lee2001}. Acredita-se muito que a Web Semântica será o próximo passo evolutivo da Web, pois possui uma linguagem semântica muito rica, e.g., \emph{Web Ontology Language\footnote{Web Ontology Language - http://www.w3.org/TR/owl-feature}}.

		Como somos expostos a muitas informações de diversas maneiras, não sabemos lidar com o que exatamente é correto ou útil para nós, resultando em uma ``sobrecarga de informação". Observamos duas características importantes para este fenômeno: demasiado volume e a falta de uma definição semântica interpretável por programas e sistemas \cite{Freitas}.

		Algumas áreas estudadas na Inteligência Artificial casou muito bem, pelo fato de serem mecânismos que captam a semântica do contéudo e se ajustam de acordo com as necessidades. Uma das abordagens propostas era de dotar a Internet de inteligência própria, construindo páginas mais elaboradas e ricas semânticamente e onde agentes pudessem raciocinar sobre semântica, logo, modelando uma Web Semântica.

		A semântica é obtida através de ontologias, que são modelos de dados representando o conhecimento adquirido sobre um mundo ou parte deste em um conjunto de conceitos existentes em um dominio e os relacionamentos entre estes. As ontologias descrevem geralmente: indivíduos, classes, atributos e relacionamentos.

		\subsubsection{Camadas da Web Semântica}

		O orgão \emph{W3C (World-Wide Web Consortium)} tem contribuido na questão de manter padrões para a \emph{World-Wide Web}, inclusive para a Web Semântica. Tem padronizado linguagens para definição de ontologias. A figura~\ref{fig:camadasW3C} é uma ilustração das camadas propostas pela \emph{W3C} para a Web Semântica.
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.6]{./figuras/camadas-w3c.png}				
			\end{center}
			\caption{Camadas propostas pela W3C}
            \label{fig:camadasW3C} 
		\end{figure}
		
	\begin{itemize}	  

		\item \textbf{CAMADA UNICODE/URI}
		Primeira cada temos o Unicode e o URI. Unicode para a padronização dos conjuntos de caracteres e o URI para a identificação e localização de páginas.

		\item \textbf{CAMADA XML}
		Na segunda camada, encontramos o XML. É uma meta-linguagem de editoração, permitindo a representação de outras linguagens padronizadas.
		
		\item \textbf{CAMADA RDF}
		Na terceira camada é adicionada mais semântica a um documento, descrevendo recursos da Web sem se referir a estruturação. Descreve os recursos por meio de sentenças. Os recursos podem ser partes de um documento ou dados, geralmente descritos como um trio com sujeito-predicato-objeto (recurso-atributo-valor do atributo). Comumente são ilustradas como um grafo direto rotulado ou através de XML.
		
	 
		\item \textbf{CAMADA de ONTOLOGIA}
		É a camada responsável pela expressividade e representação das ontologias através da extensibilidade do RDF. Existem algumas linguagens padronizadas: DAML, OWL, entre outras.
		
		Permitem definir propriedades como: listas, restrições, cardinalidades, tipos de dados, etc
	
		\item \textbf{CAMADA de LÓGICA, PROVA e CONFIANÇA}
		Esta camada ainda não possui características certas, pois ainda estão sendo estudadas. A parte lógica tem como objetivo especificar regras que atuam sobre instâncias e recursos. A camada de prova executa e a camada de confiança verifica se a prova está correta ou não.
		
		Alguns protótipos disponíveis são DAML-L e RuleML.
		
	\end{itemize}
		
		Teoricamente, podemos dar um exemplo simples de como a Web Semântica funcionaria em nossas vidas. Por exemplo, assistindo ao filme \emph{Star Wars I} na sessão da tarde, ficamos nostalgiados e gostariamos de comprar a coleção completa dos filmes. Uma ilustração de uma pequena parte da ontologia do universo de \emph{Star Wars} pode ser observada na figura~\ref{fig:starwars}. 
		
		A Web Semântica nos auxiliaria da seguinte maneira: em vários sites teriamos os dados já existentes para nós, seres humanos, lermos e metadados para os computadores tratarem. Com os metadados e todas as camadas acima explicadas, toda a rede estaria escrita através de regras, RDF e tags de XML. Então poderiamos utilizar um aplicativo e este nos retornaria lojas onde os preços estariam baratos, ou ainda mais, ele próprio avaliaria seguindo um critério custo-beneficio descrito pelo usuário, realizaria a compra e debitaria em nossa conta.		
		
		\begin{figure}[htb]
			\begin{center}				
				\includegraphics[scale=0.6]{./figuras/semanticweb-starwars.png}				
			\end{center}
			\caption{Ilustração simples de uma semântica baseado em StarWars.}
            \label{fig:starwars}
		\end{figure}
				
		Muitos problemas são enfrentados nesta área de estudo, mas grandes avanços vem ocorrendo. Como fazer a ontologia chegar ao usuário comum sem ser tão complicado, como assegurar que o conteúdo será sempre preciso e claro, padrões ontológicos, entre outros são as discussões atualmente direcionando as pesquisas nesta área.
